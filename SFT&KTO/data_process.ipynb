{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **UIUC@CHAT**"
      ],
      "metadata": {
        "id": "pbd5prUEhhPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json"
      ],
      "metadata": {
        "id": "hz0y9xSF5lHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"./final_judge.csv\"\n",
        "data_csv = pd.read_csv(data_file)"
      ],
      "metadata": {
        "id": "Ff-rlsY_5fZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Latest Dataset"
      ],
      "metadata": {
        "id": "nXkYIdFh3sC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ya11GqZ-4Eko",
        "outputId": "7a29eb82-787e-4bd7-85c8-1213f00788da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "460573028c804b5483f254defc18aa58"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"CAII-NCSA/ECE_RAG_critique_judge\", token=\"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\")\n",
        "train_set = dataset[\"train\"]\n",
        "\n",
        "print(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cogg3gY3udG",
        "outputId": "3bde17ce-945a-4664-a30c-f7242ac42fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set[0][\"question\"])\n",
        "# print(train_set[0][\"first_answer\"])\n",
        "# print(train_set[0][\"answer\"])\n",
        "print(train_set.features)"
      ],
      "metadata": {
        "id": "VBHx4PvH4emH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to Llama3 Instruct Template"
      ],
      "metadata": {
        "id": "UkR1txDNd7b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "Please analyze and respond to the following question using the excerpts from the provided documents. These documents can be pdf files or web pages. Additionally, you may see the output from API calls (calld 'tools') to the user's services which, when relevant, you should use to construct your answer. You may also see image descriptions from images uploaded by the user. Prioritize image descriptions, when helpful, to construct your answer.\n",
        "\n",
        "Integrate relevant information from these documents, ensuring each reference is linked to the document's number.\n",
        "\n",
        "Your response should be semi-formal.\n",
        "\n",
        "When quoting directly, cite with footnotes linked to the document number and page number, if provided.\n",
        "\n",
        "Summarize or paraphrase other relevant information with inline citations, again referencing the document number and page number, if provided.\n",
        "\n",
        "If the answer is not in the provided documents, state so. Yet always provide as helpful a response as possible to directly answer the question.\n",
        "\n",
        "Conclude your response with a LIST of the document titles as clickable placeholders, each linked to its respective document number and page number, if provided.\n",
        "\n",
        "Always share page numbers if they were shared with you.\n",
        "\n",
        "ALWAYS follow the examples below:\n",
        "\n",
        "Insert an inline citation like this in your response:\n",
        "\n",
        "\"[1]\" if you're referencing the first document or\n",
        "\n",
        "\"[1, page: 2]\" if you're referencing page 2 of the first document.\n",
        "\n",
        "At the end of your response, list the document title with a clickable link, like this:\n",
        "\n",
        "\"1. [document_name](#)\" if you're referencing the first document or\n",
        "\n",
        "\"1. [document_name, page: 2](#)\" if you're referencing page 2 of the first document.\n",
        "\n",
        "Nothing else should prefixxed or suffixed to the citation or document name. Consecutive citations should be separated by a comma.\n",
        "\n",
        "\n",
        "\n",
        "Suppose a document name is shared with you along with the index and pageNumber below like \"27: www.pdf, page: 2\", \"28: www.osd\", \"29: pdf.www, page 11\\n15\" where 27, 28, 29 are indices, www.pdf, www.osd, pdf.www are document_name, and 2, 11 are the pageNumbers and 15 is the content of the document, then inline citations and final list of cited documents should ALWAYS be in the following format:\n",
        "\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "The sky is blue. [27, page: 2][28] The grass is green. [29, page: 11]\n",
        "\n",
        "Relevant Sources:\n",
        "\n",
        "\n",
        "\n",
        "27. [www.pdf, page: 2](#)\n",
        "\n",
        "28. [www.osd](#)\n",
        "\n",
        "29. [pdf.www, page: 11](#)\n",
        "\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "ONLY return the documents with relevant information and cited in the response. If there are no relevant sources, don't include the \"Relevant Sources\" section in response.\n",
        "\n",
        "The following are excerpts from the high-quality documents, APIs/tools, and image descriptions to construct your answer.\\n\n",
        "\"\"\"\n",
        "\n",
        "print(system_message)"
      ],
      "metadata": {
        "id": "rG2Jln3lYL-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_conversation(sample):\n",
        "  user_message = \"\"\"\n",
        "    Here's high quality passages from the user's documents. Use these, and cite them carefully in the format previously described, to construct your answer:\n",
        "    {}\n",
        "    Finally, please respond to the user's query: {}\n",
        "  \"\"\".format(sample[\"RAG\"], sample[\"question\"])\n",
        "  assistant_message = sample[\"answer\"].replace(\"Based on the critiques, I will improve the response by addressing the weaknesses and incorporating the suggestions. Here is the revised answer:\\n\", \"\")\n",
        "  sample[\"messages\"] = [{\"role\": \"system\", \"content\": system_message}] + [{\"role\": \"user\", \"content\": user_message}] + [{\"role\": \"assistant\", \"content\": assistant_message}]\n",
        "  return sample\n",
        "\n",
        "columns_to_remove = list(train_set.features)\n",
        "columns_to_remove.remove(\"question\")\n",
        "columns_to_remove.remove(\"answer\")"
      ],
      "metadata": {
        "id": "jnYtKWbnd_OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_set.map(create_conversation, remove_columns=columns_to_remove, batched=False)\n",
        "train_set = train_set.remove_columns(\"question\")\n",
        "train_set = train_set.remove_columns(\"answer\")\n",
        "train_set.to_json(\"sft_train_dataset.json\", orient=\"records\", force_ascii=False)"
      ],
      "metadata": {
        "id": "BGleMeeXeHwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "994c1f7f541a4db4ae08914a810f895f",
            "f2bc9b9af3c447229e9ff89f7dab4111",
            "807625c77e27436fb6390668e6eddf27",
            "a1155931189b44daa8265fd9824862cf",
            "ab5f885658ad440baaa688823f3feab1",
            "ba896e3da0ac469fb91669b4475e83d1",
            "f5945f4869a04a3c8640c1e2cfc1c06f",
            "8501499b7970405f849d79d4ca9d54bd",
            "875dbebdbc7947c2915424d9b4d80a8d",
            "5a3f5fefbc0d4cffaa63f5634a2560aa",
            "ddeafed31cb043dca4ac12ef9c9cad25",
            "b90354ac188d475c8b725b25a87c66fd",
            "6d034bfefc6749a8a85c91cb4b45ada7",
            "3581905263074feaa708afe29b6ba37b",
            "31a3ce7e51fa43939e078de1f3391bdb",
            "979eb7ad4b3e477ba62775b8464ea2e5",
            "93ba3a97b92d4efb8671f1dbd540f9f6",
            "976a78f2a29b48ea9b5b0af807e6a884",
            "29597e7563fe48f6a713a93a60d4ce6d",
            "e378ab7670f14606a6c1d28f6a73d328",
            "8715b38db72c4e44a66c3dd3d63d2d92",
            "c594243581064f929663f5f7cb00d032"
          ]
        },
        "outputId": "e17fe092-f440-4f6d-c1d1-39ab887a7821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3553 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "994c1f7f541a4db4ae08914a810f895f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b90354ac188d475c8b725b25a87c66fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28358977"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check prepared dataset"
      ],
      "metadata": {
        "id": "JflK47Xofz5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "train_set = load_dataset(\"json\", data_files=\"sft_train_dataset.json\", split=\"train\")\n",
        "print(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-peUE4Wf3rV",
        "outputId": "8a4fb266-1e84-4f3a-c4de-55692d9f1d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['messages'],\n",
            "    num_rows: 3553\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = 2\n",
        "print(\"\\n---------------------------------------------  \", train_set[test_sample][\"messages\"][0][\"role\"], \"  --------------------------------------------------\\n\")\n",
        "print(train_set[0][\"messages\"][0][\"content\"])\n",
        "print(\"\\n---------------------------------------------  \", train_set[test_sample][\"messages\"][1][\"role\"], \"  --------------------------------------------------\\n\")\n",
        "print(train_set[0][\"messages\"][1][\"content\"])\n",
        "print(\"\\n---------------------------------------------  \", train_set[test_sample][\"messages\"][2][\"role\"], \"  --------------------------------------------------\\n\")\n",
        "print(train_set[0][\"messages\"][2][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpUXZOQZgCkt",
        "outputId": "b1961965-5c39-47d1-8b84-935d3eccd33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------------------------   system   --------------------------------------------------\n",
            "\n",
            "\n",
            "Please analyze and respond to the following question using the excerpts from the provided documents. These documents can be pdf files or web pages. Additionally, you may see the output from API calls (calld 'tools') to the user's services which, when relevant, you should use to construct your answer. You may also see image descriptions from images uploaded by the user. Prioritize image descriptions, when helpful, to construct your answer.\n",
            "\n",
            "Integrate relevant information from these documents, ensuring each reference is linked to the document's number.\n",
            "\n",
            "Your response should be semi-formal.\n",
            "\n",
            "When quoting directly, cite with footnotes linked to the document number and page number, if provided.\n",
            "\n",
            "Summarize or paraphrase other relevant information with inline citations, again referencing the document number and page number, if provided.\n",
            "\n",
            "If the answer is not in the provided documents, state so. Yet always provide as helpful a response as possible to directly answer the question.\n",
            "\n",
            "Conclude your response with a LIST of the document titles as clickable placeholders, each linked to its respective document number and page number, if provided.\n",
            "\n",
            "Always share page numbers if they were shared with you.\n",
            "\n",
            "ALWAYS follow the examples below:\n",
            "\n",
            "Insert an inline citation like this in your response:\n",
            "\n",
            "\"[1]\" if you're referencing the first document or\n",
            "\n",
            "\"[1, page: 2]\" if you're referencing page 2 of the first document.\n",
            "\n",
            "At the end of your response, list the document title with a clickable link, like this:\n",
            "\n",
            "\"1. [document_name](#)\" if you're referencing the first document or\n",
            "\n",
            "\"1. [document_name, page: 2](#)\" if you're referencing page 2 of the first document.\n",
            "\n",
            "Nothing else should prefixxed or suffixed to the citation or document name. Consecutive citations should be separated by a comma.\n",
            "\n",
            "\n",
            "\n",
            "Suppose a document name is shared with you along with the index and pageNumber below like \"27: www.pdf, page: 2\", \"28: www.osd\", \"29: pdf.www, page 11\n",
            "15\" where 27, 28, 29 are indices, www.pdf, www.osd, pdf.www are document_name, and 2, 11 are the pageNumbers and 15 is the content of the document, then inline citations and final list of cited documents should ALWAYS be in the following format:\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "The sky is blue. [27, page: 2][28] The grass is green. [29, page: 11]\n",
            "\n",
            "Relevant Sources:\n",
            "\n",
            "\n",
            "\n",
            "27. [www.pdf, page: 2](#)\n",
            "\n",
            "28. [www.osd](#)\n",
            "\n",
            "29. [pdf.www, page: 11](#)\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "ONLY return the documents with relevant information and cited in the response. If there are no relevant sources, don't include the \"Relevant Sources\" section in response.\n",
            "\n",
            "The following are excerpts from the high-quality documents, APIs/tools, and image descriptions to construct your answer.\n",
            "\n",
            "\n",
            "\n",
            "---------------------------------------------   user   --------------------------------------------------\n",
            "\n",
            "\n",
            "    Here's high quality passages from the user's documents. Use these, and cite them carefully in the format previously described, to construct your answer:\n",
            "    [{'title': 'Certifications', 'text': 'Choose the certification that fits your career path:\\nCertified Crop Adviser - CCA\\n Steps to Certification \\n CCA Exam Information \\n CCA Credential Forms \\n CCA Certification Renewals \\n CCA Directory: Find a Certified Professional \\n Check CCA CEUs \\nSpecialty Certifications\\n 4R Nutrient Management Specialty (4R NMS) Certification \\n California Nitrogen Management Specialty (CA-NSp) Certification \\n Prec', 'url': 'https://www.certifiedcropadviser.org/become-certified/certifications/?acsSsoAuthCheck=1'}, {'title': 'Become Certified', 'text': 'Being certified adds credibility and shows that you are serious about what you do. When you become certified, you join more than 13,000 of your peers in the largest, most recognized agriculturally-oriented certification program in North America. This program’s professional standards are widely respected by industry, academia, and government and are referenced in statutes. Once certified you are te', 'url': 'https://wwwtest.certifiedcropadviser.org/become-certified/?acsSsoAuthCheck=1'}, {'title': 'Certification List', 'text': 'This examination will test a basic knowledge of the structure of an HTML page, and the workings of essential elements such as header, paragraph and form tags. \\n You need to be logged in to take this examination. Log in or register\\n\\nThis examination will test a basic knowledge of CSS, how to include it in web pages and fundamental CSS processes such as positioning and text formatting. \\n This examin', 'url': 'https://www.the-cca.org/certification-list/'}]\n",
            "    Finally, please respond to the user's query: How do I get a CCA certification?\n",
            "  \n",
            "\n",
            "---------------------------------------------   assistant   --------------------------------------------------\n",
            "\n",
            "\n",
            "**How to Get a CCA Certification: A Step-by-Step Guide**\n",
            "\n",
            "As a crop adviser, obtaining a Certified Crop Adviser (CCA) certification is a great way to demonstrate your expertise and commitment to your career. The CCA certification is the largest and most recognized agriculturally-oriented certification program in North America, with over 13,000 professionals already certified. By following these six simple steps, you can get started on your path to becoming a certified crop adviser.\n",
            "\n",
            "**Step 1: Choose the Certification that Fits Your Career Path**\n",
            "\n",
            "From the \"Certifications\" page, you'll see that there are different types of certifications available. For this answer, we'll focus on the CCA certification.\n",
            "\n",
            "**Step 2: Review the CCA Exam Information**\n",
            "\n",
            "From the \"CCA Exam Information\" page, you can learn more about the exam format, content, and requirements. The exam is designed to test your knowledge of crop management, soil science, entomology, plant pathology, and weed science.\n",
            "\n",
            "**Step 3: Download and Complete the CCA Credential Forms**\n",
            "\n",
            "From the \"CCA Credential Forms\" page, you can download the necessary forms to apply for the certification. You'll need to provide information about your education, experience, and professional affiliations.\n",
            "\n",
            "**Step 4: Apply for the Certification**\n",
            "\n",
            "Fill out the credential forms and submit them for review. You'll need to pay the application fee and provide any additional required documents.\n",
            "\n",
            "**Step 5: Pass the CCA Exam**\n",
            "\n",
            "Once your application is approved, you'll be able to take the CCA exam. The exam is a written test that covers the five core areas of crop management, soil science, entomology, plant pathology, and weed science.\n",
            "\n",
            "**Step 6: Maintain Your Certification through Continuing Education**\n",
            "\n",
            "After becoming certified, you'll need to complete continuing education units (CEUs) to maintain your certification. You'll need to complete a certain number of CEUs every year to stay certified.\n",
            "\n",
            "**Benefits of Becoming a Certified Crop Adviser**\n",
            "\n",
            "Becoming a certified crop adviser offers many benefits, including:\n",
            "\n",
            "* Increased credibility and recognition in the industry\n",
            "* Improved job prospects and career advancement opportunities\n",
            "* Stay up-to-date with the latest knowledge and best practices in crop management\n",
            "* Networking opportunities with other professionals in the field\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "Obtaining a CCA certification is a great way to demonstrate your expertise and commitment to your career as a crop adviser. By following these six simple steps, you can get started on your path to becoming a certified crop adviser. Remember to review the CCA Exam Information page and the CCA Credential Forms page to ensure you have all the necessary information to apply for the certification. Good luck!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Special Tokens"
      ],
      "metadata": {
        "id": "WhKyjLXE4m9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWp-i8zo5L5-",
        "outputId": "31d2c0f2-f572-47cd-ef86-444619c77e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token 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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpI-LLka5qjJ",
        "outputId": "0b412630-e3c7-4bd2-c258-a1b3b468e8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "LLAMA_3_CHAT_TEMPLATE=\"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.chat_template = LLAMA_3_CHAT_TEMPLATE\n",
        "def template_dataset(examples):\n",
        "  return {\"text\": tokenizer.apply_chat_template(examples[\"messages\"], tokenize=False)}\n",
        "\n",
        "train_set = load_dataset(\"json\", data_files=\"sft_train_dataset.json\", split=\"train\")\n",
        "train_set = train_set.map(template_dataset, remove_columns=[\"messages\"])\n",
        "\n",
        "print(\"train_set:\", train_set)\n",
        "print(\"Example:\", train_set[0][\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f001a202ad6549da8c83c4cede0d95f9",
            "f77b6667ed62426c9a1d63e0b86d4d7b",
            "56fc295681224f51b523fdcca4a99f2a",
            "31c640c8bd3943e19d9ea5b0ae5cbc84",
            "0c56a63cd0cd413dbb0d370e27eac4d5",
            "0290434e02794c7b8d44b176d6671385",
            "455d3023e7d14984bc6ad94169ab5290",
            "ec5fa7d505184fb69aa74a85cc543a21",
            "daa1f4f59c4340378b9b57af16c182b1",
            "14c0d208ff254b9f878732db90d2d156",
            "0474f03c90ab47239da7c846c8b4c80a",
            "c40253c11e4d4386ad4e2bf3d3841a10",
            "1584805ad86d4916be3ad727a02f98d9",
            "b7e62b9a4b2e42379556db02624b16a0",
            "f119bc086f734325b5370b5b057ecd23",
            "47395ef9cd1745f695109aa6eef65f8c",
            "3a6eeb6ed2104e30bbbc23d16b6bea0a",
            "5ccfd8f6de9c49c790fc28ecade6d691",
            "9da5764d4f544443a4533b08c92f7705",
            "0902f27680f44011956ac76339e27381",
            "fd9ea34a1b40415ea15d3649f22b10d3",
            "e91103d82acf409f99923fb6437bbe75",
            "5b5776cf4f7842d499470ceba5c16df1",
            "7b33959be0d94dfdb1d01e7780133c9a",
            "768f4aeb86a24552a2404ac5e7c0f3e1",
            "92583dd8b95b4ec0a43541dc2b1d30e4",
            "d1206dbf538043bc9f1ac8580165fcc6",
            "a6335ee89f204551ac7bdd8e90f4413f",
            "8cf7a01a233641aabda1ec141221e8ad",
            "dadb03e25f01466193170aed8fe39e79",
            "14b5bb4c8994466bb1484870f5734b11",
            "8394ef8e0d3a4796b145bd3e100e009c",
            "70caa71666c14cc584483813189901d2",
            "97a6129c4af5474d9ff467b2b5321860",
            "45735663369c43668286de8c4ef7700c",
            "deb7f585096144d484857d81d2756143",
            "aa1b2fd4a77e455a90a2e6be494a2cdd",
            "d8359947c9c94f22a367911afcd8fa19",
            "5b8a29498cb343f08de4deea013eda2f",
            "bbf60cd6df984c9698307e603a707128",
            "4ae1dd14c7054e6097e7b99546e98350",
            "d140678eaf704ca489a1ee68a2ff8b84",
            "47d8c5b24bd241c4a8a7b7143c883a54",
            "bbea86ef68e140f49d320c9102d66d9a"
          ]
        },
        "id": "TDGqchN11xlt",
        "outputId": "1fca8fb0-f8fc-48a4-f832-6d47c2d0ae5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f001a202ad6549da8c83c4cede0d95f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c40253c11e4d4386ad4e2bf3d3841a10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b5776cf4f7842d499470ceba5c16df1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3553 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97a6129c4af5474d9ff467b2b5321860"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set: Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 3553\n",
            "})\n",
            "Example: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Please analyze and respond to the following question using the excerpts from the provided documents. These documents can be pdf files or web pages. Additionally, you may see the output from API calls (calld 'tools') to the user's services which, when relevant, you should use to construct your answer. You may also see image descriptions from images uploaded by the user. Prioritize image descriptions, when helpful, to construct your answer.\n",
            "\n",
            "Integrate relevant information from these documents, ensuring each reference is linked to the document's number.\n",
            "\n",
            "Your response should be semi-formal.\n",
            "\n",
            "When quoting directly, cite with footnotes linked to the document number and page number, if provided.\n",
            "\n",
            "Summarize or paraphrase other relevant information with inline citations, again referencing the document number and page number, if provided.\n",
            "\n",
            "If the answer is not in the provided documents, state so. Yet always provide as helpful a response as possible to directly answer the question.\n",
            "\n",
            "Conclude your response with a LIST of the document titles as clickable placeholders, each linked to its respective document number and page number, if provided.\n",
            "\n",
            "Always share page numbers if they were shared with you.\n",
            "\n",
            "ALWAYS follow the examples below:\n",
            "\n",
            "Insert an inline citation like this in your response:\n",
            "\n",
            "\"[1]\" if you're referencing the first document or\n",
            "\n",
            "\"[1, page: 2]\" if you're referencing page 2 of the first document.\n",
            "\n",
            "At the end of your response, list the document title with a clickable link, like this:\n",
            "\n",
            "\"1. [document_name](#)\" if you're referencing the first document or\n",
            "\n",
            "\"1. [document_name, page: 2](#)\" if you're referencing page 2 of the first document.\n",
            "\n",
            "Nothing else should prefixxed or suffixed to the citation or document name. Consecutive citations should be separated by a comma.\n",
            "\n",
            "\n",
            "\n",
            "Suppose a document name is shared with you along with the index and pageNumber below like \"27: www.pdf, page: 2\", \"28: www.osd\", \"29: pdf.www, page 11\n",
            "15\" where 27, 28, 29 are indices, www.pdf, www.osd, pdf.www are document_name, and 2, 11 are the pageNumbers and 15 is the content of the document, then inline citations and final list of cited documents should ALWAYS be in the following format:\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "The sky is blue. [27, page: 2][28] The grass is green. [29, page: 11]\n",
            "\n",
            "Relevant Sources:\n",
            "\n",
            "\n",
            "\n",
            "27. [www.pdf, page: 2](#)\n",
            "\n",
            "28. [www.osd](#)\n",
            "\n",
            "29. [pdf.www, page: 11](#)\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "ONLY return the documents with relevant information and cited in the response. If there are no relevant sources, don't include the \"Relevant Sources\" section in response.\n",
            "\n",
            "The following are excerpts from the high-quality documents, APIs/tools, and image descriptions to construct your answer.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Here's high quality passages from the user's documents. Use these, and cite them carefully in the format previously described, to construct your answer:\n",
            "    [{'title': 'Certifications', 'text': 'Choose the certification that fits your career path:\\nCertified Crop Adviser - CCA\\n Steps to Certification \\n CCA Exam Information \\n CCA Credential Forms \\n CCA Certification Renewals \\n CCA Directory: Find a Certified Professional \\n Check CCA CEUs \\nSpecialty Certifications\\n 4R Nutrient Management Specialty (4R NMS) Certification \\n California Nitrogen Management Specialty (CA-NSp) Certification \\n Prec', 'url': 'https://www.certifiedcropadviser.org/become-certified/certifications/?acsSsoAuthCheck=1'}, {'title': 'Become Certified', 'text': 'Being certified adds credibility and shows that you are serious about what you do. When you become certified, you join more than 13,000 of your peers in the largest, most recognized agriculturally-oriented certification program in North America. This program’s professional standards are widely respected by industry, academia, and government and are referenced in statutes. Once certified you are te', 'url': 'https://wwwtest.certifiedcropadviser.org/become-certified/?acsSsoAuthCheck=1'}, {'title': 'Certification List', 'text': 'This examination will test a basic knowledge of the structure of an HTML page, and the workings of essential elements such as header, paragraph and form tags. \\n You need to be logged in to take this examination. Log in or register\\n\\nThis examination will test a basic knowledge of CSS, how to include it in web pages and fundamental CSS processes such as positioning and text formatting. \\n This examin', 'url': 'https://www.the-cca.org/certification-list/'}]\n",
            "    Finally, please respond to the user's query: How do I get a CCA certification?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "**How to Get a CCA Certification: A Step-by-Step Guide**\n",
            "\n",
            "As a crop adviser, obtaining a Certified Crop Adviser (CCA) certification is a great way to demonstrate your expertise and commitment to your career. The CCA certification is the largest and most recognized agriculturally-oriented certification program in North America, with over 13,000 professionals already certified. By following these six simple steps, you can get started on your path to becoming a certified crop adviser.\n",
            "\n",
            "**Step 1: Choose the Certification that Fits Your Career Path**\n",
            "\n",
            "From the \"Certifications\" page, you'll see that there are different types of certifications available. For this answer, we'll focus on the CCA certification.\n",
            "\n",
            "**Step 2: Review the CCA Exam Information**\n",
            "\n",
            "From the \"CCA Exam Information\" page, you can learn more about the exam format, content, and requirements. The exam is designed to test your knowledge of crop management, soil science, entomology, plant pathology, and weed science.\n",
            "\n",
            "**Step 3: Download and Complete the CCA Credential Forms**\n",
            "\n",
            "From the \"CCA Credential Forms\" page, you can download the necessary forms to apply for the certification. You'll need to provide information about your education, experience, and professional affiliations.\n",
            "\n",
            "**Step 4: Apply for the Certification**\n",
            "\n",
            "Fill out the credential forms and submit them for review. You'll need to pay the application fee and provide any additional required documents.\n",
            "\n",
            "**Step 5: Pass the CCA Exam**\n",
            "\n",
            "Once your application is approved, you'll be able to take the CCA exam. The exam is a written test that covers the five core areas of crop management, soil science, entomology, plant pathology, and weed science.\n",
            "\n",
            "**Step 6: Maintain Your Certification through Continuing Education**\n",
            "\n",
            "After becoming certified, you'll need to complete continuing education units (CEUs) to maintain your certification. You'll need to complete a certain number of CEUs every year to stay certified.\n",
            "\n",
            "**Benefits of Becoming a Certified Crop Adviser**\n",
            "\n",
            "Becoming a certified crop adviser offers many benefits, including:\n",
            "\n",
            "* Increased credibility and recognition in the industry\n",
            "* Improved job prospects and career advancement opportunities\n",
            "* Stay up-to-date with the latest knowledge and best practices in crop management\n",
            "* Networking opportunities with other professionals in the field\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "Obtaining a CCA certification is a great way to demonstrate your expertise and commitment to your career as a crop adviser. By following these six simple steps, you can get started on your path to becoming a certified crop adviser. Remember to review the CCA Exam Information page and the CCA Credential Forms page to ensure you have all the necessary information to apply for the certification. Good luck!<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build KTO Dataset"
      ],
      "metadata": {
        "id": "WHn-HODy6IC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXuGn8Tg_XvB",
        "outputId": "886135d5-2e02-417d-83f0-f5124be56b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"CAII-NCSA/ECE_RAG_critique_judge\", token=\"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\")\n",
        "train_set = dataset[\"train\"]\n",
        "\n",
        "print(train_set)\n",
        "print(train_set.features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "4ea89ee24482433ca955829eab7f5d8e",
            "2566f89f24744f13b796910927d9f2b3",
            "b670d305c6c74ee989501a907d8e4701",
            "4277bb1694b246f798c30b617ebe2f5b",
            "cef8c05563fb4d8b82f2bdc11ea04d14",
            "88c8091d41804636a7a8300e468186b6",
            "38657ed2423342e4a7c00b9a32a4bbdc",
            "6427fda8b58d4341bf80d28d91c4b60e",
            "62ba1320571949c4b9d63d7e4f008e8c",
            "654b687252c84f019076a9743e75dbab",
            "4a549b179c5b48bd8fe3c31fe6c67baa",
            "d3fbdf5a4f014cca88bda7a31a5d22c8",
            "e39d3cfffd9548b88fb9dd72a7ced4b6",
            "6ff47172a3084c2eb627c1973837d4b6",
            "a17a50936e8a450187326d2aa57d08fe",
            "818391ba631e4ec08328e664c35596db",
            "768ae83bf2b24e5289b44122261a3f28",
            "db3ece1f93744b6d9cbfa7fc0eb7179a",
            "af46ef25a0bf418f9812c068cb13d610",
            "7a43ca692be84108a03ab1ba22ccd16f",
            "80301fff3d9e44c8b15a6c1944694c70",
            "966eeb299a28401689879ecfb21bf3e8",
            "6e7fc75c22d64b9a8e7acaa88ad0e608",
            "57896832616c48bd90fc6081aba6d5c6",
            "adba4257fbba4707be4e30ed676d0d90",
            "cac2d1a687704a3ba2f90afa7b9b9f19",
            "86a36a03eea94bfcaf113253fac613b9",
            "6788a91a5da14dd4bebb85ce2b7fee0c",
            "628664cb888e4ae18a952cb3a836eb82",
            "39f9c51948864b4c9658bee0b6703680",
            "41f8012e6d564dd5beb7cc41b4d61260",
            "b6956ba1ab0a451db521393c76767248",
            "6416eb426118429bbc67304481fc1191"
          ]
        },
        "id": "wsV-v8Af6Ho8",
        "outputId": "c585ffff-5709-4b9d-a7b5-e155e545c128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ea89ee24482433ca955829eab7f5d8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/71.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3fbdf5a4f014cca88bda7a31a5d22c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e7fc75c22d64b9a8e7acaa88ad0e608"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['question', 'RAG', 'first_answer', 'factuality', 'usefulness', 'helpfulness', 'freshness', 'examples', 'answer', 'llm_judge', 'llm_judge_score', 'llm_judge_score_revised', 'llm_judge_70B', 'llm_judge_score_70B'],\n",
            "    num_rows: 3553\n",
            "})\n",
            "{'question': Value(dtype='string', id=None), 'RAG': Value(dtype='string', id=None), 'first_answer': Value(dtype='string', id=None), 'factuality': Value(dtype='string', id=None), 'usefulness': Value(dtype='string', id=None), 'helpfulness': Value(dtype='string', id=None), 'freshness': Value(dtype='string', id=None), 'examples': Value(dtype='string', id=None), 'answer': Value(dtype='string', id=None), 'llm_judge': Value(dtype='string', id=None), 'llm_judge_score': Value(dtype='float64', id=None), 'llm_judge_score_revised': Value(dtype='float64', id=None), 'llm_judge_70B': Value(dtype='string', id=None), 'llm_judge_score_70B': Value(dtype='float64', id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Dataset**"
      ],
      "metadata": {
        "id": "563I_z4n7a5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "questions = []\n",
        "rag = []\n",
        "answers = []\n",
        "labels = []\n",
        "\n",
        "good_len = 0\n",
        "bad_len = 0\n",
        "\n",
        "for idx in range(len(train_set)):\n",
        "  if train_set[idx]['llm_judge_score_70B'] is None:\n",
        "    continue\n",
        "  elif train_set[idx]['llm_judge_score_70B'] >= 5:\n",
        "    questions.append(train_set[idx][\"question\"])\n",
        "    rag.append(train_set[idx][\"RAG\"])\n",
        "    answers.append(train_set[idx][\"answer\"])\n",
        "    labels.append(True)\n",
        "    good_len += 1\n",
        "  elif train_set[idx]['llm_judge_score_70B'] <= 3:\n",
        "    questions.append(train_set[idx][\"question\"])\n",
        "    rag.append(train_set[idx][\"RAG\"])\n",
        "    answers.append(train_set[idx][\"answer\"])\n",
        "    labels.append(False)\n",
        "    bad_len += 1\n",
        "\n",
        "kto_dict = {\"question\":questions, \"RAG\":rag, \"answer\":answers, \"label\":labels}\n",
        "\n",
        "kto_dataset = Dataset.from_dict(kto_dict)\n",
        "\n",
        "print(\"kto_dataset:\", kto_dataset)\n",
        "print(\"good_len:\", good_len)\n",
        "print(\"bad_len:\", bad_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4j_Yjbn7aKD",
        "outputId": "1b1cabb3-05b9-4ccd-d6e9-cee94627e646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kto_dataset: Dataset({\n",
            "    features: ['question', 'RAG', 'answer', 'label'],\n",
            "    num_rows: 1614\n",
            "})\n",
            "good_len: 1225\n",
            "bad_len: 389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transform to Template**"
      ],
      "metadata": {
        "id": "hzy4q8aZ_8nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "Please analyze and respond to the following question using the excerpts from the provided documents. These documents can be pdf files or web pages. Additionally, you may see the output from API calls (calld 'tools') to the user's services which, when relevant, you should use to construct your answer. You may also see image descriptions from images uploaded by the user. Prioritize image descriptions, when helpful, to construct your answer.\n",
        "\n",
        "Integrate relevant information from these documents, ensuring each reference is linked to the document's number.\n",
        "\n",
        "Your response should be semi-formal.\n",
        "\n",
        "When quoting directly, cite with footnotes linked to the document number and page number, if provided.\n",
        "\n",
        "Summarize or paraphrase other relevant information with inline citations, again referencing the document number and page number, if provided.\n",
        "\n",
        "If the answer is not in the provided documents, state so. Yet always provide as helpful a response as possible to directly answer the question.\n",
        "\n",
        "Conclude your response with a LIST of the document titles as clickable placeholders, each linked to its respective document number and page number, if provided.\n",
        "\n",
        "Always share page numbers if they were shared with you.\n",
        "\n",
        "ALWAYS follow the examples below:\n",
        "\n",
        "Insert an inline citation like this in your response:\n",
        "\n",
        "\"[1]\" if you're referencing the first document or\n",
        "\n",
        "\"[1, page: 2]\" if you're referencing page 2 of the first document.\n",
        "\n",
        "At the end of your response, list the document title with a clickable link, like this:\n",
        "\n",
        "\"1. [document_name](#)\" if you're referencing the first document or\n",
        "\n",
        "\"1. [document_name, page: 2](#)\" if you're referencing page 2 of the first document.\n",
        "\n",
        "Nothing else should prefixxed or suffixed to the citation or document name. Consecutive citations should be separated by a comma.\n",
        "\n",
        "\n",
        "\n",
        "Suppose a document name is shared with you along with the index and pageNumber below like \"27: www.pdf, page: 2\", \"28: www.osd\", \"29: pdf.www, page 11\\n15\" where 27, 28, 29 are indices, www.pdf, www.osd, pdf.www are document_name, and 2, 11 are the pageNumbers and 15 is the content of the document, then inline citations and final list of cited documents should ALWAYS be in the following format:\n",
        "\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "The sky is blue. [27, page: 2][28] The grass is green. [29, page: 11]\n",
        "\n",
        "Relevant Sources:\n",
        "\n",
        "\n",
        "\n",
        "27. [www.pdf, page: 2](#)\n",
        "\n",
        "28. [www.osd](#)\n",
        "\n",
        "29. [pdf.www, page: 11](#)\n",
        "\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "ONLY return the documents with relevant information and cited in the response. If there are no relevant sources, don't include the \"Relevant Sources\" section in response.\n",
        "\n",
        "The following are excerpts from the high-quality documents, APIs/tools, and image descriptions to construct your answer.\\n\n",
        "\"\"\"\n",
        "\n",
        "print(system_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R87kwa1N7Xb9",
        "outputId": "b79f0914-6c81-4693-dcbb-ed12b81c2f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Please analyze and respond to the following question using the excerpts from the provided documents. These documents can be pdf files or web pages. Additionally, you may see the output from API calls (calld 'tools') to the user's services which, when relevant, you should use to construct your answer. You may also see image descriptions from images uploaded by the user. Prioritize image descriptions, when helpful, to construct your answer.\n",
            "\n",
            "Integrate relevant information from these documents, ensuring each reference is linked to the document's number.\n",
            "\n",
            "Your response should be semi-formal.\n",
            "\n",
            "When quoting directly, cite with footnotes linked to the document number and page number, if provided.\n",
            "\n",
            "Summarize or paraphrase other relevant information with inline citations, again referencing the document number and page number, if provided.\n",
            "\n",
            "If the answer is not in the provided documents, state so. Yet always provide as helpful a response as possible to directly answer the question.\n",
            "\n",
            "Conclude your response with a LIST of the document titles as clickable placeholders, each linked to its respective document number and page number, if provided.\n",
            "\n",
            "Always share page numbers if they were shared with you.\n",
            "\n",
            "ALWAYS follow the examples below:\n",
            "\n",
            "Insert an inline citation like this in your response:\n",
            "\n",
            "\"[1]\" if you're referencing the first document or\n",
            "\n",
            "\"[1, page: 2]\" if you're referencing page 2 of the first document.\n",
            "\n",
            "At the end of your response, list the document title with a clickable link, like this:\n",
            "\n",
            "\"1. [document_name](#)\" if you're referencing the first document or\n",
            "\n",
            "\"1. [document_name, page: 2](#)\" if you're referencing page 2 of the first document.\n",
            "\n",
            "Nothing else should prefixxed or suffixed to the citation or document name. Consecutive citations should be separated by a comma.\n",
            "\n",
            "\n",
            "\n",
            "Suppose a document name is shared with you along with the index and pageNumber below like \"27: www.pdf, page: 2\", \"28: www.osd\", \"29: pdf.www, page 11\n",
            "15\" where 27, 28, 29 are indices, www.pdf, www.osd, pdf.www are document_name, and 2, 11 are the pageNumbers and 15 is the content of the document, then inline citations and final list of cited documents should ALWAYS be in the following format:\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "The sky is blue. [27, page: 2][28] The grass is green. [29, page: 11]\n",
            "\n",
            "Relevant Sources:\n",
            "\n",
            "\n",
            "\n",
            "27. [www.pdf, page: 2](#)\n",
            "\n",
            "28. [www.osd](#)\n",
            "\n",
            "29. [pdf.www, page: 11](#)\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "ONLY return the documents with relevant information and cited in the response. If there are no relevant sources, don't include the \"Relevant Sources\" section in response.\n",
            "\n",
            "The following are excerpts from the high-quality documents, APIs/tools, and image descriptions to construct your answer.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_completion(sample):\n",
        "  user_message = \"\"\"\n",
        "    Here's high quality passages from the user's documents. Use these, and cite them carefully in the format previously described, to construct your answer:\n",
        "    {}\n",
        "    Finally, please respond to the user's query: {}\n",
        "  \"\"\".format(sample[\"RAG\"], sample[\"question\"])\n",
        "  assistant_message = sample[\"answer\"].replace(\"Based on the critiques, I will improve the response by addressing the weaknesses and incorporating the suggestions. Here is the revised answer:\\n\", \"\")\n",
        "  sample[\"prompt\"] = [{\"role\": \"system\", \"content\": system_message}] + [{\"role\": \"user\", \"content\": user_message}] + [{\"role\": \"assistant\", \"content\": \"\"}]\n",
        "  sample[\"completion\"] = [{\"role\": \"system\", \"content\": system_message}] + [{\"role\": \"user\", \"content\": user_message}] + [{\"role\": \"assistant\", \"content\": assistant_message}]\n",
        "  sample[\"label\"] = sample[\"label\"]\n",
        "  return sample\n",
        "\n",
        "kto_set = kto_dataset.map(create_prompt_completion, batched=False)\n",
        "kto_set = kto_set.remove_columns(\"question\")\n",
        "kto_set = kto_set.remove_columns(\"RAG\")\n",
        "kto_set = kto_set.remove_columns(\"answer\")\n",
        "kto_set.to_json(\"kto_dataset.json\", orient=\"records\", force_ascii=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "980c60ff267a4083a3b43e452388f8f1",
            "8c8bbd423bd44e4d85a843c1dddb6b78",
            "2c059dc0122746e1b2df3606897f796f",
            "1dbbd990c7b84dfb84492a4c68032b6b",
            "1ca2baabc5974b3f94bf374027383eac",
            "e5eea796088e4e5aa5f842091dc29fd2",
            "c8164e5cd9804908ac4ebcd58b1fe4f8",
            "02c446582c5846cb8cfb0ad1b504ac3a",
            "c66bc396e30144268efb179ddf874e7a",
            "843a19f7fd774b8fb6e097e3d9d2ff64",
            "9e078c6f6a8f40c8be9c9db911aba6eb",
            "3cd985eed4cf46c5b6b675ac53efd289",
            "52d0bd19d1414131a21fd68c35a056c7",
            "c62a3d6a32b34fd1800973d5a2343a04",
            "86f2f1e181e44231829a64f1893de12d",
            "b12e01d4e13048059d55b4e56a61f3fc",
            "e37156cec8b94dc4b53872e27669c990",
            "6b28a6ef92ad47a5afa4c9ddbd3e2681",
            "ec13be7e376b4bd18b78cb6912b0e5ce",
            "20fb2caca0874c16a7f70adf05273c26",
            "b2b0bbfbcf1244a89458cbf53c92f28b",
            "d1fd8b5676094f8888a38ecc7bb79dde"
          ]
        },
        "id": "wZLkrI1eAICo",
        "outputId": "2d8d5fe1-2fc7-4493-e0ef-e161d639ca39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1614 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "980c60ff267a4083a3b43e452388f8f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cd985eed4cf46c5b6b675ac53efd289"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21455853"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check KTO Dataset**"
      ],
      "metadata": {
        "id": "57Z10uWNCk52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "kto_set = load_dataset(\"json\", data_files=\"kto_dataset.json\", split=\"train\")\n",
        "print(kto_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "2359a89fa1914873896de4ad2a7a40d3",
            "4fc27fd176f64eb7bf8eb1356ea7a153",
            "ef84485c553f4187a0d43fd6420ebccf",
            "dabcab1703ba40b082438b3b46a33dd7",
            "151b7a2be045475eb53ffab49bb70474",
            "9c8909b795854e9284778dd88b1b64c7",
            "09cb2e31548d4e2db0a0b9b72050900f",
            "4f335aaff0cb45659e9955bc099afbed",
            "b6938b14532743548465b8845becf156",
            "5eaffae3d95347beb6c4f359e0bb1895",
            "d2a7bc107a3a4ad8905cf990e134451a"
          ]
        },
        "id": "HDGRO9KgCkMk",
        "outputId": "a5fa8db9-724c-4ed3-fb8f-a2900cd80cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2359a89fa1914873896de4ad2a7a40d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['label', 'prompt', 'completion'],\n",
            "    num_rows: 1614\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add Special Token**"
      ],
      "metadata": {
        "id": "E6YFTyqwC3gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token 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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVNdifSXC9cI",
        "outputId": "82b6c377-ce69-48fd-9257-7aa6ef90d036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "LLAMA_3_CHAT_TEMPLATE=\"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.chat_template = LLAMA_3_CHAT_TEMPLATE\n",
        "def template_dataset(examples):\n",
        "  return {\"prompt\": tokenizer.apply_chat_template(examples[\"prompt\"], tokenize=False), \"completion\": tokenizer.apply_chat_template(examples[\"completion\"], tokenize=False), \"label\":examples[\"label\"]}\n",
        "\n",
        "kto_set = load_dataset(\"json\", data_files=\"kto_dataset.json\", split=\"train\")\n",
        "kto_set = kto_set.map(template_dataset)\n",
        "\n",
        "print(\"kto_set:\", kto_set)\n",
        "print(\"Example:\")\n",
        "print(\"Prompt:\", kto_set[0][\"prompt\"])\n",
        "print(\"Completion:\", kto_set[0][\"completion\"])\n",
        "print(\"Label:\", kto_set[0][\"label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "85ae039ef4b745958501f908db5854ef",
            "ac82cd48c94640e187c3cb321c7146af",
            "cc00d99ef6d243c4967a7cbcbe0ac971",
            "9d140abc6bea4e8f9374edfb4d50c9e2",
            "0540c4c4f3634b61acf6b41da01a0c22",
            "71bd56d0503f497185922d4e77fbb0d0",
            "90e9bf9a19b14769be3fb4f363665815",
            "af8f3a8b38444db383bcfb41ddba5011",
            "7b90a19aca2241c1ac2a0eaec0907965",
            "410b4a1806544c9ba8fdaa5e66761a07",
            "65a320e7526a4169bec1c26f6785263e",
            "40cf45fa8f1848379e41545468efec95",
            "2c3592b62dcc4dcea0febacc0f549326",
            "9286af9baa4e410885e76132fb8fd2ca",
            "512b22b6239e4418a304e7c0a987625a",
            "e43f02c0bc7445de8379d7e2eec60af5",
            "85271793c9644a9b939530074cefb929",
            "da4b194cc62342b78a72a7cdb7a8dcb6",
            "dde172fc71d94254b3f62f6f336de818",
            "1bbf59a489664337bffbcb71fa14594a",
            "f2e26f1df42845a490fe123bebd4c4c2",
            "609445fbce274d8bbd84f4d376b5e1f2",
            "1ae95582f55e48af85e845af97b6c06d",
            "9c6214afc42a48faa0e51e379348143f",
            "1ea1111d446747408b7ddbd60ecbbe44",
            "453e69bafa294b75ba12e2e69e9cfb96",
            "4102e58f54ea4570acd4f9002278d478",
            "db3e1a3658b84e71b4662c3bc70cd995",
            "2b0c8dcbbd7e4dd489a8bc09fbe52bde",
            "855129ae602d41219caa5e985d73605e",
            "d14616d39efe475d93d0329c106186a7",
            "96aec33073bc4714984b69dd12b32571",
            "4c78f5a18839499d9ed6f480f67de630",
            "62b1d0e5898e4dab984351234bd6ee96",
            "ae5c1a523e4644b3b767413d69c12de0",
            "bebad1f83d284288980072ddbd898b47",
            "1cdf7921d2e64dc581aefedfb4996e62",
            "20d88e6dcf254ad59897bb8848322dce",
            "ba7eaee0837d4fe7a189f4ec2c9493e5",
            "106607373fc243f5a0ae8c5dc7faa3b9",
            "c7b108089fc04e5d892d3dc399c0b7a7",
            "c254fd0308c64254857f2e33dfe38f08",
            "0865717616e848399c73112f1fc4404b",
            "6c68dcf9e9c94bf1936c6707d6276b55"
          ]
        },
        "id": "99LptS3kC6Ud",
        "outputId": "9501b485-1e65-4655-c35a-06a611532ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85ae039ef4b745958501f908db5854ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40cf45fa8f1848379e41545468efec95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ae95582f55e48af85e845af97b6c06d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1614 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62b1d0e5898e4dab984351234bd6ee96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kto_set: Dataset({\n",
            "    features: ['label', 'prompt', 'completion'],\n",
            "    num_rows: 1614\n",
            "})\n",
            "Example:\n",
            "Prompt: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Please analyze and respond to the following question using the excerpts from the provided documents. These documents can be pdf files or web pages. Additionally, you may see the output from API calls (calld 'tools') to the user's services which, when relevant, you should use to construct your answer. You may also see image descriptions from images uploaded by the user. Prioritize image descriptions, when helpful, to construct your answer.\n",
            "\n",
            "Integrate relevant information from these documents, ensuring each reference is linked to the document's number.\n",
            "\n",
            "Your response should be semi-formal.\n",
            "\n",
            "When quoting directly, cite with footnotes linked to the document number and page number, if provided.\n",
            "\n",
            "Summarize or paraphrase other relevant information with inline citations, again referencing the document number and page number, if provided.\n",
            "\n",
            "If the answer is not in the provided documents, state so. Yet always provide as helpful a response as possible to directly answer the question.\n",
            "\n",
            "Conclude your response with a LIST of the document titles as clickable placeholders, each linked to its respective document number and page number, if provided.\n",
            "\n",
            "Always share page numbers if they were shared with you.\n",
            "\n",
            "ALWAYS follow the examples below:\n",
            "\n",
            "Insert an inline citation like this in your response:\n",
            "\n",
            "\"[1]\" if you're referencing the first document or\n",
            "\n",
            "\"[1, page: 2]\" if you're referencing page 2 of the first document.\n",
            "\n",
            "At the end of your response, list the document title with a clickable link, like this:\n",
            "\n",
            "\"1. [document_name](#)\" if you're referencing the first document or\n",
            "\n",
            "\"1. [document_name, page: 2](#)\" if you're referencing page 2 of the first document.\n",
            "\n",
            "Nothing else should prefixxed or suffixed to the citation or document name. Consecutive citations should be separated by a comma.\n",
            "\n",
            "\n",
            "\n",
            "Suppose a document name is shared with you along with the index and pageNumber below like \"27: www.pdf, page: 2\", \"28: www.osd\", \"29: pdf.www, page 11\n",
            "15\" where 27, 28, 29 are indices, www.pdf, www.osd, pdf.www are document_name, and 2, 11 are the pageNumbers and 15 is the content of the document, then inline citations and final list of cited documents should ALWAYS be in the following format:\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "The sky is blue. [27, page: 2][28] The grass is green. [29, page: 11]\n",
            "\n",
            "Relevant Sources:\n",
            "\n",
            "\n",
            "\n",
            "27. [www.pdf, page: 2](#)\n",
            "\n",
            "28. [www.osd](#)\n",
            "\n",
            "29. [pdf.www, page: 11](#)\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "ONLY return the documents with relevant information and cited in the response. If there are no relevant sources, don't include the \"Relevant Sources\" section in response.\n",
            "\n",
            "The following are excerpts from the high-quality documents, APIs/tools, and image descriptions to construct your answer.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Here's high quality passages from the user's documents. Use these, and cite them carefully in the format previously described, to construct your answer:\n",
            "    [{'title': 'Parallel Reduction with CUDA', 'text': 'Finding the minimum of very large arrays using GPUs Note: This post is intended for users with a considerable background in GPU hardware and CUDA programming Photo by Nana Dua on Unsplash Parallel reduction refers to algorithms which combine an array of elements producing a single value as a result. Problems eligible for this algorithm include those which involve operators that are associative and', 'url': 'https://shreeraman-ak.medium.com/parallel-reduction-with-cuda-d0ae10c1ae2c?source=post_internal_links---------1----------------------------'}, {'title': 'cuda Tutorial => Single-warp parallel reduction using registers only', 'text': 'Example\\nTypically, reduction is performed on global or shared array.\\nHowever, when the reduction is performed on a very small scale, as a part of a bigger CUDA kernel, it can be performed with a single warp.\\nWhen that happens, on Keppler or higher architectures (CC>=3.0), it is possible to use warp-shuffle functions to avoid using shared memory at all.\\nSuppose for example, that each thread in a wa', 'url': 'https://riptutorial.com/cuda/example/22462/single-warp-parallel-reduction-using-registers-only'}, {'title': 'cuda Tutorial => Single-warp parallel reduction for commutative...', 'text': 'Example\\nSometimes the reduction has to be performed on a very small scale, as a part of a bigger CUDA kernel.\\nSuppose for example, that the input data has exactly 32 elements - the number of threads in a warp.\\nIn such scenario a single warp can be assigned to perform the reduction.\\nGiven that warp executes in a perfect sync, many __syncthreads() instructions can be removed - when compared to a blo', 'url': 'https://riptutorial.com/cuda/example/22460/single-warp-parallel-reduction-for-commutative-operator'}]\n",
            "    Finally, please respond to the user's query: how does a parallel reduction kernel reduce the input of the an array of floats<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "<|eot_id|>\n",
            "Completion: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Please analyze and respond to the following question using the excerpts from the provided documents. These documents can be pdf files or web pages. Additionally, you may see the output from API calls (calld 'tools') to the user's services which, when relevant, you should use to construct your answer. You may also see image descriptions from images uploaded by the user. Prioritize image descriptions, when helpful, to construct your answer.\n",
            "\n",
            "Integrate relevant information from these documents, ensuring each reference is linked to the document's number.\n",
            "\n",
            "Your response should be semi-formal.\n",
            "\n",
            "When quoting directly, cite with footnotes linked to the document number and page number, if provided.\n",
            "\n",
            "Summarize or paraphrase other relevant information with inline citations, again referencing the document number and page number, if provided.\n",
            "\n",
            "If the answer is not in the provided documents, state so. Yet always provide as helpful a response as possible to directly answer the question.\n",
            "\n",
            "Conclude your response with a LIST of the document titles as clickable placeholders, each linked to its respective document number and page number, if provided.\n",
            "\n",
            "Always share page numbers if they were shared with you.\n",
            "\n",
            "ALWAYS follow the examples below:\n",
            "\n",
            "Insert an inline citation like this in your response:\n",
            "\n",
            "\"[1]\" if you're referencing the first document or\n",
            "\n",
            "\"[1, page: 2]\" if you're referencing page 2 of the first document.\n",
            "\n",
            "At the end of your response, list the document title with a clickable link, like this:\n",
            "\n",
            "\"1. [document_name](#)\" if you're referencing the first document or\n",
            "\n",
            "\"1. [document_name, page: 2](#)\" if you're referencing page 2 of the first document.\n",
            "\n",
            "Nothing else should prefixxed or suffixed to the citation or document name. Consecutive citations should be separated by a comma.\n",
            "\n",
            "\n",
            "\n",
            "Suppose a document name is shared with you along with the index and pageNumber below like \"27: www.pdf, page: 2\", \"28: www.osd\", \"29: pdf.www, page 11\n",
            "15\" where 27, 28, 29 are indices, www.pdf, www.osd, pdf.www are document_name, and 2, 11 are the pageNumbers and 15 is the content of the document, then inline citations and final list of cited documents should ALWAYS be in the following format:\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "The sky is blue. [27, page: 2][28] The grass is green. [29, page: 11]\n",
            "\n",
            "Relevant Sources:\n",
            "\n",
            "\n",
            "\n",
            "27. [www.pdf, page: 2](#)\n",
            "\n",
            "28. [www.osd](#)\n",
            "\n",
            "29. [pdf.www, page: 11](#)\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "ONLY return the documents with relevant information and cited in the response. If there are no relevant sources, don't include the \"Relevant Sources\" section in response.\n",
            "\n",
            "The following are excerpts from the high-quality documents, APIs/tools, and image descriptions to construct your answer.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Here's high quality passages from the user's documents. Use these, and cite them carefully in the format previously described, to construct your answer:\n",
            "    [{'title': 'Parallel Reduction with CUDA', 'text': 'Finding the minimum of very large arrays using GPUs Note: This post is intended for users with a considerable background in GPU hardware and CUDA programming Photo by Nana Dua on Unsplash Parallel reduction refers to algorithms which combine an array of elements producing a single value as a result. Problems eligible for this algorithm include those which involve operators that are associative and', 'url': 'https://shreeraman-ak.medium.com/parallel-reduction-with-cuda-d0ae10c1ae2c?source=post_internal_links---------1----------------------------'}, {'title': 'cuda Tutorial => Single-warp parallel reduction using registers only', 'text': 'Example\\nTypically, reduction is performed on global or shared array.\\nHowever, when the reduction is performed on a very small scale, as a part of a bigger CUDA kernel, it can be performed with a single warp.\\nWhen that happens, on Keppler or higher architectures (CC>=3.0), it is possible to use warp-shuffle functions to avoid using shared memory at all.\\nSuppose for example, that each thread in a wa', 'url': 'https://riptutorial.com/cuda/example/22462/single-warp-parallel-reduction-using-registers-only'}, {'title': 'cuda Tutorial => Single-warp parallel reduction for commutative...', 'text': 'Example\\nSometimes the reduction has to be performed on a very small scale, as a part of a bigger CUDA kernel.\\nSuppose for example, that the input data has exactly 32 elements - the number of threads in a warp.\\nIn such scenario a single warp can be assigned to perform the reduction.\\nGiven that warp executes in a perfect sync, many __syncthreads() instructions can be removed - when compared to a blo', 'url': 'https://riptutorial.com/cuda/example/22460/single-warp-parallel-reduction-for-commutative-operator'}]\n",
            "    Finally, please respond to the user's query: how does a parallel reduction kernel reduce the input of the an array of floats<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Based on the initial response, I will improve the answer by addressing the critiques and suggestions provided.\n",
            "\n",
            "**Improved Answer:**\n",
            "\n",
            "Parallel Reduction with CUDA: A Comprehensive Guide\n",
            "\n",
            "Parallel reduction is a fundamental concept in CUDA programming, allowing developers to combine elements of an array in a parallel manner. This process is particularly useful when dealing with large datasets, as it can significantly reduce the computation time required for reduction operations.\n",
            "\n",
            "In this answer, we will provide a step-by-step guide to parallel reduction with CUDA, including the use of warp-shuffle functions, register-based reduction, and block reduction. We will also discuss the importance of commutative operators and provide a simple example code snippet to illustrate the concept.\n",
            "\n",
            "**Step 1: Warp-Wise Reduction**\n",
            "\n",
            "The first step in parallel reduction is to divide the input array into warps, each consisting of 32 threads. Each thread in the warp is responsible for reducing a single element of the array.\n",
            "\n",
            "**Step 2: Register-Based Reduction**\n",
            "\n",
            "Within each warp, the threads perform a series of register-based reductions using the warp-shuffle functions. These functions allow threads to exchange values with each other without using shared memory.\n",
            "\n",
            "**Step 3: Warp Reduction**\n",
            "\n",
            "The results of the register-based reductions are then combined using a commutative operator (e.g., addition) to produce a single value per warp.\n",
            "\n",
            "**Step 4: Block Reduction**\n",
            "\n",
            "The results from each warp are combined using a reduction operation to produce a single value per block.\n",
            "\n",
            "**Step 5: Global Reduction**\n",
            "\n",
            "The results from each block are combined using a reduction operation to produce the final result.\n",
            "\n",
            "**Example Code:**\n",
            "\n",
            "Here is a simple example code snippet that demonstrates single-warp parallel reduction using registers only:\n",
            "```cuda\n",
            "__global__ void reduction(float *input, float *output) {\n",
            "    __shared__ float sdata[32];\n",
            "\n",
            "    int idx = threadIdx.x;\n",
            "    float val = input[idx];\n",
            "\n",
            "    // Register-based reduction\n",
            "    for (int i = 1; i < 32; i *= 2) {\n",
            "        __shfl_down(val, i);\n",
            "        val += __shfl_down(val, i);\n",
            "    }\n",
            "\n",
            "    // Store the reduced value in shared memory\n",
            "    sdata[idx] = val;\n",
            "\n",
            "    // Block reduction\n",
            "    __syncthreads();\n",
            "    for (int i = 16; i > 0; i >>= 1) {\n",
            "        if (idx < i)\n",
            "            sdata[idx] += sdata[idx + i];\n",
            "    }\n",
            "\n",
            "    // Write the final result to global memory\n",
            "    if (idx == 0)\n",
            "        output[0] = sdata[0];\n",
            "}\n",
            "```\n",
            "**Optimization Techniques:**\n",
            "\n",
            "To optimize the reduction process, developers can use various techniques, such as:\n",
            "\n",
            "1. **Register blocking:** Divide the input array into smaller blocks and perform the reduction operation on each block separately.\n",
            "2. **Shared memory optimization:** Use shared memory to store intermediate results and reduce global memory access.\n",
            "3. **Warp-level parallelism:** Use warp-level parallelism to perform the reduction operation in parallel, reducing the number of global memory accesses.\n",
            "4. ** Error handling:** Implement error handling mechanisms to handle edge cases, such as small arrays or non-associative operators.\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "In conclusion, parallel reduction is a powerful technique for combining elements of an array in a parallel manner. By understanding the warp-shuffle functions, register-based reduction, and block reduction, developers can create efficient and scalable parallel reduction kernels. The provided example code snippet demonstrates single-warp parallel reduction using registers only, and developers can use optimization techniques to further improve the performance of their parallel reduction kernels.\n",
            "\n",
            "**Additional Resources:**\n",
            "\n",
            "For more information on parallel reduction with CUDA, I recommend the following resources:\n",
            "\n",
            "* NVIDIA's CUDA documentation: <https://docs.nvidia.com/cuda/>\n",
            "* CUDA By Example: <https://developer.download.nvidia.com/assets/cuda/files/cuda-by-example.pdf>\n",
            "* Parallel Reduction with CUDA: <https://developer.download.nvidia.com/assets/cuda/files/parallel-reduction.pdf>\n",
            "\n",
            "I hope this improved answer provides a comprehensive guide to parallel reduction with CUDA. If you have any further questions or concerns, please feel free to ask.<|eot_id|>\n",
            "Label: True\n"
          ]
        }
      ]
    }
  ]
}