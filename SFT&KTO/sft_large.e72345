[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO] Starting elastic_operator with launch configs:
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   entrypoint       : ./KTO2.py
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   min_nodes        : 2
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   max_nodes        : 2
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   nproc_per_node   : 2
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   run_id           : 21534
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   rdzv_backend     : c10d
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   rdzv_endpoint    : 172.24.192.105:29500
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   rdzv_configs     : {'timeout': 900}
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   max_restarts     : 0
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO] Starting elastic_operator with launch configs:
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   entrypoint       : ./KTO2.py
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   min_nodes        : 2
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   max_nodes        : 2
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   nproc_per_node   : 2
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   run_id           : 21534
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   rdzv_backend     : c10d
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   rdzv_endpoint    : 172.24.192.105:29500
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   rdzv_configs     : {'timeout': 900}
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   max_restarts     : 0
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   monitor_interval : 5
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   log_dir          : None
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO]   metrics_cfg      : {}
[2024-05-31 17:50:01,195] torch.distributed.launcher.api: [INFO] 
[2024-05-31 17:50:01,199] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] log directory set to: /tmp/torchelastic_kzskam2y/21534_vswb1w9q
[2024-05-31 17:50:01,199] torch.distributed.elastic.agent.server.api: [INFO] [default] starting workers for entrypoint: python3.10
[2024-05-31 17:50:01,199] torch.distributed.elastic.agent.server.api: [INFO] [default] Rendezvous'ing worker group
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   monitor_interval : 5
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   log_dir          : None
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO]   metrics_cfg      : {}
[2024-05-31 17:50:01,211] torch.distributed.launcher.api: [INFO] 
[2024-05-31 17:50:01,215] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] log directory set to: /tmp/torchelastic_owmhoglw/21534_h0xzbliy
[2024-05-31 17:50:01,215] torch.distributed.elastic.agent.server.api: [INFO] [default] starting workers for entrypoint: python3.10
[2024-05-31 17:50:01,215] torch.distributed.elastic.agent.server.api: [INFO] [default] Rendezvous'ing worker group
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO] [default] Rendezvous complete for workers. Result:
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   restart_count=0
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   master_addr=hydro05.internal.ncsa.edu
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   master_port=19465
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   group_rank=0
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   group_world_size=2
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   local_ranks=[0, 1]
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   role_ranks=[0, 1]
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   global_ranks=[0, 1]
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   role_world_sizes=[4, 4]
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO]   global_world_sizes=[4, 4]
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO] 
[2024-05-31 17:50:02,376] torch.distributed.elastic.agent.server.api: [INFO] [default] Starting worker group
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO] [default] Rendezvous complete for workers. Result:
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   restart_count=0
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   master_addr=hydro05.internal.ncsa.edu
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   master_port=19465
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   group_rank=1
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   group_world_size=2
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   local_ranks=[0, 1]
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   role_ranks=[2, 3]
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   global_ranks=[2, 3]
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   role_world_sizes=[4, 4]
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO]   global_world_sizes=[4, 4]
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO] 
[2024-05-31 17:50:02,377] torch.distributed.elastic.multiprocessing: [INFO] Setting worker0 reply file to: /tmp/torchelastic_kzskam2y/21534_vswb1w9q/attempt_0/0/error.json
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.api: [INFO] [default] Starting worker group
[2024-05-31 17:50:02,377] torch.distributed.elastic.multiprocessing: [INFO] Setting worker1 reply file to: /tmp/torchelastic_kzskam2y/21534_vswb1w9q/attempt_0/1/error.json
[2024-05-31 17:50:02,377] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
[2024-05-31 17:50:02,377] torch.distributed.elastic.multiprocessing: [INFO] Setting worker0 reply file to: /tmp/torchelastic_owmhoglw/21534_h0xzbliy/attempt_0/0/error.json
[2024-05-31 17:50:02,377] torch.distributed.elastic.multiprocessing: [INFO] Setting worker1 reply file to: /tmp/torchelastic_owmhoglw/21534_h0xzbliy/attempt_0/1/error.json
2024-05-31 17:50:08.339078: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-31 17:50:08.339249: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-31 17:50:08.342611: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-31 17:50:08.342664: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.
  warnings.warn(warning_msg)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.
  warnings.warn(warning_msg)
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.
  warnings.warn(warning_msg)
Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.
  warnings.warn(warning_msg)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:417: UserWarning: When using DPODataCollatorWithPadding, you should set `max_length` in the KTOTrainer's init it will be set to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:457: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your KTOConfig we have set it for you, but you should do it yourself in the future.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:417: UserWarning: When using DPODataCollatorWithPadding, you should set `max_length` in the KTOTrainer's init it will be set to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:457: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your KTOConfig we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:417: UserWarning: When using DPODataCollatorWithPadding, you should set `max_length` in the KTOTrainer's init it will be set to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:457: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your KTOConfig we have set it for you, but you should do it yourself in the future.
  warnings.warn(
Tokenizing train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Tokenizing train dataset:  28%|██▊       | 1000/3552 [00:01<00:04, 592.28 examples/s]/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:417: UserWarning: When using DPODataCollatorWithPadding, you should set `max_length` in the KTOTrainer's init it will be set to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:457: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your KTOConfig we have set it for you, but you should do it yourself in the future.
  warnings.warn(
Tokenizing train dataset:  56%|█████▋    | 2000/3552 [00:03<00:02, 595.18 examples/s]Tokenizing train dataset:  84%|████████▍ | 3000/3552 [00:05<00:00, 595.77 examples/s]Tokenizing train dataset: 100%|██████████| 3552/3552 [00:05<00:00, 603.22 examples/s]Tokenizing train dataset: 100%|██████████| 3552/3552 [00:06<00:00, 590.21 examples/s]
Extracting KL train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Extracting KL train dataset:   2%|▏         | 68/3552 [00:00<00:05, 659.34 examples/s]Extracting KL train dataset:   4%|▍         | 144/3552 [00:00<00:07, 474.14 examples/s]Extracting KL train dataset:   6%|▌         | 212/3552 [00:00<00:07, 454.71 examples/s]Extracting KL train dataset:   8%|▊         | 284/3552 [00:00<00:06, 524.33 examples/s]Extracting KL train dataset:  10%|▉         | 352/3552 [00:00<00:05, 565.43 examples/s]Extracting KL train dataset:  12%|█▏        | 424/3552 [00:00<00:05, 603.43 examples/s]Extracting KL train dataset:  14%|█▍        | 496/3552 [00:00<00:04, 629.88 examples/s]Extracting KL train dataset:  16%|█▌        | 568/3552 [00:00<00:04, 638.69 examples/s]Extracting KL train dataset:  18%|█▊        | 640/3552 [00:01<00:04, 649.08 examples/s]Extracting KL train dataset:  20%|█▉        | 708/3552 [00:01<00:04, 654.00 examples/s]Extracting KL train dataset:  22%|█Tokenizing train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Tokenizing train dataset:  28%|██▊       | 1000/3552 [00:01<00:04, 612.01 examples/s]Tokenizing train dataset:  56%|█████▋    | 2000/3552 [00:03<00:02, 612.41 examples/s]Tokenizing train dataset:  84%|████████▍ | 3000/3552 [00:04<00:00, 616.03 examples/s]Tokenizing train dataset: 100%|██████████| 3552/3552 [00:05<00:00, 616.30 examples/s]Tokenizing train dataset: 100%|██████████| 3552/3552 [00:05<00:00, 604.47 examples/s]
█▏       | 780/3552 [00:01<00:04, 667.36 examples/s]Extracting KL train dataset:  24%|██▍       | 852/3552 [00:01<00:04, 672.38 examples/s]Extracting KL train dataset:  26%|██▌       | 924/3552 [00:01<00:03, 669.55 examples/s]Extracting KL train dataset:  28%|██▊       | 996/3552 [00:01<00:03, 666.76 examples/s]Extracting KL train dataset:  30%|██▉       | 1064/3552 [00:01<00:03, 667.98 examples/s]Extracting KL train dataset:  32%|███▏      | 1136/3552 [00:01<00:03, 676.03 examples/s]Extracting KL train dataset:  34%|███▍      | 1208/3552 [00:01<00:03, 674.74 examples/s]Extracting KL train dataset:  36%|███▌      | 1276/3552 [00:02<00:03, 669.48 examples/s]Extracting KL train dataset:  38%|███▊      | 1344/3552 [00:02<00:03, 660.48 examples/s]Extracting KL train dataset:  40%|███▉      | 1412/3552 [00:02<00:03, 663.46 examples/s]Extracting KL train dataset:  42%|████▏     | 1484/3552 [00:02<00:03, 667.45 examples/s]ExtracExtracting KL train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Extracting KL train dataset:   2%|▏         | 68/3552 [00:00<00:05, 661.47 examples/s]Extracting KL train dataset:   4%|▍         | 144/3552 [00:00<00:07, 470.60 examples/s]Extracting KL train dataset:   6%|▌         | 212/3552 [00:00<00:07, 424.11 examples/s]Extracting KL train dataset:   8%|▊         | 284/3552 [00:00<00:06, 496.80 examples/s]Extracting KL train dataset:  10%|█         | 356/3552 [00:00<00:05, 551.38 examples/s]Extracting KL train dataset:  12%|█▏        | 428/3552 [00:00<00:05, 584.01 examples/s]Extracting KL train dataset:  14%|█▍        | 500/3552 [00:00<00:05, 609.23 examples/s]Extracting KL train dataset:  16%|█▌        | 568/3552 [00:01<00:04, 622.27 examples/s]Extracting KL train dataset:  18%|█▊        | 636/3552 [00:01<00:04, 629.19 examples/s]Extracting KL train dataset:  20%|█▉        | 708/3552 [00:01<00:04, 642.89 examples/s]Extracting KL train dataset:  22%|█ting KL train dataset:  44%|████▍     | 1556/3552 [00:02<00:03, 663.17 examples/s]Extracting KL train dataset:  46%|████▌     | 1628/3552 [00:02<00:02, 669.57 examples/s]Extracting KL train dataset:  48%|████▊     | 1700/3552 [00:02<00:02, 675.19 examples/s]Extracting KL train dataset:  50%|████▉     | 1772/3552 [00:02<00:02, 675.37 examples/s]Extracting KL train dataset:  52%|█████▏    | 1844/3552 [00:02<00:02, 674.06 examples/s]Extracting KL train dataset:  54%|█████▍    | 1916/3552 [00:02<00:02, 676.64 examples/s]Extracting KL train dataset:  56%|█████▌    | 1988/3552 [00:03<00:02, 679.21 examples/s]Extracting KL train dataset:  58%|█████▊    | 2060/3552 [00:03<00:02, 681.48 examples/s]Extracting KL train dataset:  61%|██████    | 2164/3552 [00:03<00:02, 673.19 examples/s]Extracting KL train dataset:  63%|██████▎   | 2236/3552 [00:03<00:01, 669.63 examples/s]Extracting KL train datase█▏       | 780/3552 [00:01<00:04, 648.86 examples/s]Extracting KL train dataset:  24%|██▍       | 852/3552 [00:01<00:04, 657.12 examples/s]Extracting KL train dataset:  26%|██▌       | 924/3552 [00:01<00:03, 664.05 examples/s]Extracting KL train dataset:  28%|██▊       | 992/3552 [00:01<00:03, 664.89 examples/s]Extracting KL train dataset:  30%|██▉       | 1064/3552 [00:01<00:03, 672.47 examples/s]Extracting KL train dataset:  32%|███▏      | 1136/3552 [00:01<00:03, 675.37 examples/s]Extracting KL train dataset:  34%|███▍      | 1204/3552 [00:01<00:03, 666.63 examples/s]Extracting KL train dataset:  36%|███▌      | 1276/3552 [00:02<00:03, 669.55 examples/s]Extracting KL train dataset:  38%|███▊      | 1344/3552 [00:02<00:03, 669.52 examples/s]Extracting KL train dataset:  40%|███▉      | 1416/3552 [00:02<00:03, 664.67 examples/s]Extracting KL train dataset:  42%|████▏     | 1488/3552 [00:02<00:03, 659.20 examples/s]Extract:  65%|██████▍   | 2308/3552 [00:03<00:01, 671.10 examples/s]Extracting KL train dataset:  67%|██████▋   | 2380/3552 [00:03<00:01, 674.79 examples/s]Extracting KL train dataset:  69%|██████▉   | 2452/3552 [00:03<00:01, 673.56 examples/s]Extracting KL train dataset:  71%|███████   | 2524/3552 [00:03<00:01, 676.05 examples/s]Extracting KL train dataset:  73%|███████▎  | 2596/3552 [00:03<00:01, 679.69 examples/s]Extracting KL train dataset:  75%|███████▌  | 2668/3552 [00:04<00:01, 671.91 examples/s]Extracting KL train dataset:  77%|███████▋  | 2736/3552 [00:04<00:01, 664.55 examples/s]Extracting KL train dataset:  79%|███████▉  | 2804/3552 [00:04<00:01, 661.54 examples/s]Extracting KL train dataset:  81%|████████  | 2876/3552 [00:04<00:01, 665.17 examples/s]Extracting KL train dataset:  83%|████████▎ | 2948/3552 [00:04<00:00, 667.82 examples/s]Extracting KL train dataset:  44%|████▍     | 1560/3552 [00:02<00:03, 663.25 examples/s]Extracting KL train dataset:  46%|████▌     | 1632/3552 [00:02<00:02, 660.23 examples/s]Extracting KL train dataset:  48%|████▊     | 1704/3552 [00:02<00:02, 661.91 examples/s]Extracting KL train dataset:  50%|█████     | 1776/3552 [00:02<00:02, 665.58 examples/s]Extracting KL train dataset:  52%|█████▏    | 1848/3552 [00:02<00:02, 669.03 examples/s]Extracting KL train dataset:  54%|█████▍    | 1916/3552 [00:03<00:02, 667.77 examples/s]Extracting KL train dataset:  56%|█████▌    | 1984/3552 [00:03<00:02, 665.20 examples/s]Extracting KL train dataset:  58%|█████▊    | 2052/3552 [00:03<00:02, 657.74 examples/s]Extracting KL train dataset:  60%|█████▉    | 2124/3552 [00:03<00:02, 661.75 examples/s]Extracting KL train dataset:  62%|██████▏   | 2196/3552 [00:03<00:02, 659.31 examples/s]Extracting KL train dataseting KL train dataset:  85%|████████▍ | 3016/3552 [00:04<00:00, 663.27 examples/s]Extracting KL train dataset:  87%|████████▋ | 3088/3552 [00:04<00:00, 663.58 examples/s]Extracting KL train dataset:  89%|████████▉ | 3160/3552 [00:04<00:00, 669.66 examples/s]Extracting KL train dataset:  91%|█████████ | 3232/3552 [00:04<00:00, 672.09 examples/s]Extracting KL train dataset:  93%|█████████▎| 3300/3552 [00:05<00:00, 670.59 examples/s]Extracting KL train dataset:  95%|█████████▍| 3372/3552 [00:05<00:00, 674.94 examples/s]Extracting KL train dataset:  97%|█████████▋| 3444/3552 [00:05<00:00, 670.18 examples/s]Extracting KL train dataset:  99%|█████████▉| 3516/3552 [00:05<00:00, 674.34 examples/s]Extracting KL train dataset: 100%|██████████| 3552/3552 [00:05<00:00, 650.44 examples/s]
t:  64%|██████▍   | 2268/3552 [00:03<00:01, 662.68 examples/s]Extracting KL train dataset:  66%|██████▌   | 2340/3552 [00:03<00:01, 662.37 examples/s]Extracting KL train dataset:  68%|██████▊   | 2412/3552 [00:03<00:01, 665.96 examples/s]Extracting KL train dataset:  70%|███████   | 2488/3552 [00:03<00:01, 669.01 examples/s]Extracting KL train dataset:  72%|███████▏  | 2560/3552 [00:03<00:01, 668.20 examples/s]Extracting KL train dataset:  74%|███████▍  | 2628/3552 [00:04<00:01, 662.72 examples/s]Extracting KL train dataset:  76%|███████▌  | 2700/3552 [00:04<00:01, 659.13 examples/s]Extracting KL train dataset:  78%|███████▊  | 2768/3552 [00:04<00:01, 660.80 examples/s]Extracting KL train dataset:  80%|███████▉  | 2836/3552 [00:04<00:01, 662.49 examples/s]Extracting KL train dataset:  82%|████████▏ | 2912/3552 [00:04<00:00, 675.04 examples/s]ExtracProcessing tokenized train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Processing tokenized train dataset:   2%|▏         | 55/3552 [00:00<00:06, 530.47 examples/s]Processing tokenized train dataset:   3%|▎         | 109/3552 [00:00<00:06, 530.16 examples/s]Processing tokenized train dataset:   5%|▍         | 163/3552 [00:00<00:06, 531.65 examples/s]Processing tokenized train dataset:   6%|▌         | 219/3552 [00:00<00:06, 537.17 examples/s]Processing tokenized train dataset:   8%|▊         | 273/3552 [00:00<00:06, 535.67 examples/s]Processing tokenized train dataset:   9%|▉         | 327/3552 [00:00<00:06, 533.40 examples/s]Processing tokenized train dataset:  11%|█         | 383/3552 [00:00<00:05, 539.69 examples/s]Processing tokenized train dataset:  13%|█▎        | 464/3552 [00:00<00:05, 535.05 examples/s]Processing tokenized train dataset:  15%|█▍        | 518/3552 [00:00<00:05, 533.70 examples/s]Processing tokenized train dataset:  16%|█▌        | 572/35ting KL train dataset:  84%|████████▍ | 2980/3552 [00:04<00:00, 669.84 examples/s]Extracting KL train dataset:  86%|████████▌ | 3052/3552 [00:04<00:00, 666.75 examples/s]Extracting KL train dataset:  88%|████████▊ | 3120/3552 [00:04<00:00, 666.41 examples/s]Extracting KL train dataset:  90%|████████▉ | 3192/3552 [00:04<00:00, 667.89 examples/s]Extracting KL train dataset:  92%|█████████▏| 3260/3552 [00:05<00:00, 663.85 examples/s]Extracting KL train dataset:  94%|█████████▎| 3328/3552 [00:05<00:00, 662.98 examples/s]Extracting KL train dataset:  96%|█████████▌| 3400/3552 [00:05<00:00, 660.48 examples/s]Extracting KL train dataset:  98%|█████████▊| 3472/3552 [00:05<00:00, 666.77 examples/s]Extracting KL train dataset: 100%|█████████▉| 3544/3552 [00:05<00:00, 665.41 examples/s]Extracting KL train dataset: 100%|██████████| 3552/3552 [00:05<00:00, 641.34 examples/s]
Processing tokenized train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Processing tokenized train dataset:   2%|▏         | 54/3552 [00:00<00:06, 527.80 examples/s]Processing tokenized train dataset:   3%|▎         | 107/3552 [00:00<00:06, 522.97 examples/s]Processing tokenized train dataset:   5%|▍         | 161/3552 [00:00<00:06, 526.22 examples/s]Processing tokenized train dataset:   6%|▌         | 217/3552 [00:00<00:06, 535.09 examples/s]Processing tokenized train dataset:   8%|▊         | 271/3552 [00:00<00:06, 535.19 examples/s]Processing tokenized train dataset:   9%|▉         | 327/3552 [00:00<00:06, 533.79 examples/s]Processing tokenized train dataset:  11%|█         | 382/3552 [00:00<00:05, 536.65 examples/s]Processing tokenized train dataset:  13%|█▎        | 462/3552 [00:00<00:05, 534.04 examples/s]Processing tokenized train dataset:  15%|█▍        | 516/3552 [00:00<00:05, 531.67 examples/s]Processing tokenized train dataset:  17%|█▋        | 595/3552 [00:01<00:05, 534.34 examples/s]Processing tokenized train dataset:  18%|█▊        | 626/3552 [00:01<00:05, 531.48 examples/s]Processing tokenized train dataset:  19%|█▉        | 680/3552 [00:01<00:05, 532.38 examples/s]Processing tokenized train dataset:  21%|██        | 735/3552 [00:01<00:05, 533.95 examples/s]Processing tokenized train dataset:  22%|██▏       | 791/3552 [00:01<00:05, 536.49 examples/s]Processing tokenized train dataset:  24%|██▍       | 846/3552 [00:01<00:05, 537.90 examples/s]Processing tokenized train dataset:  25%|██▌       | 900/3552 [00:01<00:04, 535.75 examples/s]Processing tokenized train dataset:  28%|██▊       | 978/3552 [00:01<00:04, 528.36 examples/s]Processing tokenized train dataset:  30%|██▉       | 1055/3552 [00:03<00:16, 147.43 examples/s]Processing tokenized train dataset:  31%|███▏      | 1111/3552 [00:03<00:13, 182.98 examples/s]Processing tokenized train dataset:  33%|███▎      | 1165/3552 [00:03<00:10, 221.89 examples/s]Processing tokenized train dataset:  34%|███▍      | 1221/3552 [00:03<00:08, 266.84 examples/s]Processing tokenized train dataset:  36%|███▌      | 1276/3552 [00:03<00:07, 311.11 examples/s]Processing tokenized train dataset:  37%|███▋      | 1328/3552 [00:03<00:06, 348.67 examples/s]Processing tokenized train dataset:  39%|███▉      | 1382/3552 [00:03<00:05, 387.88 examples/s]Processing tokenized train dataset:  40%|████      | 1436/3552 [00:03<00:05, 421.44 examples/s]Processing tokenized train dataset:  42%|████▏     | 1490/3552 [00:03<00:04, 448.92 examples/s]Processing tokenized train dataset:  44%|████▍     | 1569/3552 [00:04<00:04, 474.87 examples/s]Processing tokenized train dataset:  46%|████▌     | 1624/3552 [00:04<00:03, 491.56 examples/s]Processing tokenized train dataset:  47%|████▋     | 1677/3552 [00:04<00:03, 498.54 examples/s]Processing tokenized train dataset:  49%|████▉ 52 [00:01<00:05, 525.91 examples/s]Processing tokenized train dataset:  19%|█▉        | 674/3552 [00:01<00:05, 523.54 examples/s]Processing tokenized train dataset:  20%|██        | 727/3552 [00:01<00:05, 522.41 examples/s]Processing tokenized train dataset:  22%|██▏       | 781/3552 [00:01<00:05, 523.04 examples/s]Processing tokenized train dataset:  24%|██▎       | 835/3552 [00:01<00:05, 526.59 examples/s]Processing tokenized train dataset:  25%|██▌       | 889/3552 [00:01<00:05, 526.26 examples/s]Processing tokenized train dataset:  27%|██▋       | 943/3552 [00:01<00:04, 526.61 examples/s]Processing tokenized train dataset:  28%|██▊       | 996/3552 [00:01<00:04, 524.98 examples/s]Processing tokenized train dataset:  30%|██▉       | 1057/3552 [00:03<00:19, 124.95 examples/s]Processing tokenized train dataset:  31%|███▏      | 1111/3552 [00:03<00:15, 160.45 examples/s]Processing tokenized train dataset:  33%|███▎      | 1166/3552 [00:03<00:11, 202.22 examples/s]Processing tokenized train dataset:  34%|███▍      | 1219/3552 [00:03<00:09, 246.06 examples/s]Processing tokenized train dataset:  36%|███▌      | 1274/3552 [00:03<00:07, 294.70 examples/s]Processing tokenized train dataset:  37%|███▋      | 1328/3552 [00:03<00:06, 340.24 examples/s]Processing tokenized train dataset:  40%|███▉      | 1407/3552 [00:03<00:05, 391.87 examples/s]Processing tokenized train dataset:  42%|████▏     | 1486/3552 [00:03<00:04, 427.88 examples/s]Processing tokenized train dataset:  43%|████▎     | 1540/3552 [00:04<00:04, 449.61 examples/s]Processing tokenized train dataset:  45%|████▍     | 1594/3552 [00:04<00:04, 468.01 examples/s]Processing tokenized train dataset:  47%|████▋     | 1673/3552 [00:04<00:03, 485.03 examples/s]Processing tokenized train dataset:  49%|████▊     | 1726/3552 [00:04<00:03, 492.54 examples/s]Processing tokenized train dataset:  50%|████    | 1732/3552 [00:04<00:03, 506.73 examples/s]Processing tokenized train dataset:  50%|█████     | 1787/3552 [00:04<00:03, 514.88 examples/s]Processing tokenized train dataset:  52%|█████▏    | 1840/3552 [00:04<00:03, 514.88 examples/s]Processing tokenized train dataset:  53%|█████▎    | 1894/3552 [00:04<00:03, 519.27 examples/s]Processing tokenized train dataset:  55%|█████▍    | 1950/3552 [00:04<00:03, 528.67 examples/s]Processing tokenized train dataset:  57%|█████▋    | 2028/3552 [00:05<00:09, 156.84 examples/s]Processing tokenized train dataset:  59%|█████▊    | 2083/3552 [00:05<00:07, 195.02 examples/s]Processing tokenized train dataset:  60%|██████    | 2136/3552 [00:06<00:06, 235.51 examples/s]Processing tokenized train dataset:  62%|██████▏   | 2192/3552 [00:06<00:04, 281.94 examples/s]Processing tokenized train dataset:  63%|██████▎   | 2248/3552 [00:06<00:03, 329.07 examples/s]Processing tokenized train dataset:  65%|██████▍   | 2302/3552 [00:06<00:03, 368.93 examples/s]Processing tokenized train dataset:  66%|██████▋   | 2360/3552 [00:06<00:02, 412.91 examples/s]Processing tokenized train dataset:  68%|██████▊   | 2415/3552 [00:06<00:02, 442.45 examples/s]Processing tokenized train dataset:  70%|██████▉   | 2469/3552 [00:06<00:02, 464.05 examples/s]Processing tokenized train dataset:  71%|███████   | 2526/3552 [00:06<00:02, 490.97 examples/s]Processing tokenized train dataset:  73%|███████▎  | 2580/3552 [00:06<00:01, 503.02 examples/s]Processing tokenized train dataset:  74%|███████▍  | 2634/3552 [00:06<00:01, 510.83 examples/s]Processing tokenized train dataset:  76%|███████▌  | 2691/3552 [00:07<00:01, 523.91 examples/s]Processing tokenized train dataset:  78%|███████▊  | 2771/3552 [00:07<00:01, 525.44 examples/s]Processing tokenized train █     | 1780/3552 [00:04<00:03, 502.65 examples/s]Processing tokenized train dataset:  52%|█████▏    | 1833/3552 [00:04<00:03, 507.67 examples/s]Processing tokenized train dataset:  53%|█████▎    | 1888/3552 [00:04<00:03, 513.43 examples/s]Processing tokenized train dataset:  55%|█████▍    | 1941/3552 [00:04<00:03, 515.42 examples/s]Processing tokenized train dataset:  56%|█████▋    | 2000/3552 [00:05<00:10, 146.86 examples/s]Processing tokenized train dataset:  58%|█████▊    | 2055/3552 [00:05<00:08, 186.57 examples/s]Processing tokenized train dataset:  59%|█████▉    | 2108/3552 [00:06<00:06, 229.20 examples/s]Processing tokenized train dataset:  61%|██████    | 2163/3552 [00:06<00:05, 276.87 examples/s]Processing tokenized train dataset:  62%|██████▏   | 2215/3552 [00:06<00:04, 319.62 examples/s]Processing tokenized train dataset:  64%|██████▍   | 2272/3552 [00:06<00:03, 368.08 examples/s]Processing tokenized train dataset:  65%|██████▌   | 2325/3552 [00:06<00:03, 403.68 examples/s]Processing tokenized train dataset:  67%|██████▋   | 2379/3552 [00:06<00:02, 433.19 examples/s]Processing tokenized train dataset:  69%|██████▊   | 2437/3552 [00:06<00:02, 467.41 examples/s]Processing tokenized train dataset:  71%|███████   | 2518/3552 [00:06<00:02, 489.67 examples/s]Processing tokenized train dataset:  73%|███████▎  | 2597/3552 [00:06<00:01, 500.10 examples/s]Processing tokenized train dataset:  75%|███████▌  | 2676/3552 [00:07<00:01, 506.46 examples/s]Processing tokenized train dataset:  77%|███████▋  | 2729/3552 [00:07<00:01, 508.13 examples/s]Processing tokenized train dataset:  78%|███████▊  | 2784/3552 [00:07<00:01, 515.21 examples/s]Processing tokenized train dataset:  80%|███████▉  | 2838/3552 [00:07<00:01, 518.97 examples/s]Processing tokenizedataset:  80%|████████  | 2850/3552 [00:07<00:01, 524.56 examples/s]Processing tokenized train dataset:  82%|████████▏ | 2904/3552 [00:07<00:01, 526.56 examples/s]Processing tokenized train dataset:  83%|████████▎ | 2958/3552 [00:07<00:01, 527.51 examples/s]Processing tokenized train dataset:  85%|████████▌ | 3028/3552 [00:08<00:03, 162.00 examples/s]Processing tokenized train dataset:  87%|████████▋ | 3083/3552 [00:08<00:02, 199.86 examples/s]Processing tokenized train dataset:  88%|████████▊ | 3138/3552 [00:08<00:01, 242.15 examples/s]Processing tokenized train dataset:  90%|████████▉ | 3192/3552 [00:08<00:01, 284.66 examples/s]Processing tokenized train dataset:  91%|█████████▏| 3249/3552 [00:09<00:00, 333.53 examples/s]Processing tokenized train dataset:  93%|█████████▎| 3304/3552 [00:09<00:00, 374.77 examples/s]Processing tokenized train dataset:  95%|█████████▍| 3360/3552 [00:09<00:00, 413.86 examples/s]Processing tokenized train dataset:  96%|█████████▌| 3414/3552 [00:09<00:00, 441.92 examples/s]Processing tokenized train dataset:  98%|█████████▊| 3469/3552 [00:09<00:00, 466.04 examples/s]Processing tokenized train dataset:  99%|█████████▉| 3525/3552 [00:09<00:00, 488.11 examples/s]Processing tokenized train dataset: 100%|██████████| 3552/3552 [00:10<00:00, 350.85 examples/s]
d train dataset:  81%|████████▏ | 2893/3552 [00:07<00:01, 525.60 examples/s]Processing tokenized train dataset:  83%|████████▎ | 2949/3552 [00:07<00:01, 532.27 examples/s]Processing tokenized train dataset:  85%|████████▌ | 3027/3552 [00:08<00:03, 166.35 examples/s]Processing tokenized train dataset:  87%|████████▋ | 3083/3552 [00:08<00:02, 205.45 examples/s]Processing tokenized train dataset:  88%|████████▊ | 3138/3552 [00:08<00:01, 248.16 examples/s]Processing tokenized train dataset:  90%|████████▉ | 3192/3552 [00:08<00:01, 290.36 examples/s]Processing tokenized train dataset:  91%|█████████▏| 3247/3552 [00:09<00:00, 335.02 examples/s]Processing tokenized train dataset:  93%|█████████▎| 3300/3552 [00:09<00:00, 372.75 examples/s]Processing tokenized train dataset:  94%|█████████▍| 3356/3552 [00:09<00:00, 413.19 examples/s]Processing Processing tokenized train KL dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Processing tokenized train KL dataset:   1%|▏         | 53/3552 [00:00<00:06, 521.00 examples/s]Processing tokenized train KL dataset:   3%|▎         | 107/3552 [00:00<00:06, 524.22 examples/s]Processing tokenized train KL dataset:   5%|▍         | 162/3552 [00:00<00:06, 532.41 examples/s]Processing tokenized train KL dataset:   6%|▌         | 216/3552 [00:00<00:06, 531.36 examples/s]Processing tokenized train KL dataset:   8%|▊         | 271/3552 [00:00<00:06, 535.63 examples/s]Processing tokenized train KL dataset:   9%|▉         | 326/3552 [00:00<00:06, 536.50 examples/s]Processing tokenized train KL dataset:  11%|█         | 382/3552 [00:00<00:05, 541.56 examples/s]Processing tokenized train KL dataset:  13%|█▎        | 463/3552 [00:00<00:05, 538.66 examples/s]Processing tokenized train KL dataset:  15%|█▍        | 518/3552 [00:00<00:05, 538.67 examples/s]Processing tokenized train KL dattokenized train dataset:  96%|█████████▌| 3409/3552 [00:09<00:00, 440.01 examples/s]Processing tokenized train dataset:  98%|█████████▊| 3464/3552 [00:09<00:00, 467.28 examples/s]Processing tokenized train dataset:  99%|█████████▉| 3520/3552 [00:09<00:00, 489.26 examples/s]Processing tokenized train dataset: 100%|██████████| 3552/3552 [00:10<00:00, 346.64 examples/s]
Processing tokenized train KL dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Processing tokenized train KL dataset:   1%|▏         | 52/3552 [00:00<00:06, 515.49 examples/s]Processing tokenized train KL dataset:   3%|▎         | 105/3552 [00:00<00:06, 517.12 examples/s]Processing tokenized train KL dataset:   4%|▍         | 159/3552 [00:00<00:06, 523.57 examples/s]Processing tokenized train KL dataset:   6%|▌         | 213/3552 [00:00<00:06, 524.79 examples/s]Processing tokenized train KL dataset:   8%|▊         | 268/3552 [00:00<00:06, 530.66 examples/s]Processing tokenized train KL dataset:  10%|▉         | 348/3552 [00:00<00:06, 528.66 examples/s]Processing tokenized train KL dataset:  11%|█▏        | 402/3552 [00:00<00:05, 529.33 examples/s]Processing tokenized train KL dataset:  13%|█▎        | 455/3552 [00:00<00:05, 527.09 examples/s]Processing tokenized train KL dataset:  14%|█▍        | 510/3552 [00:00<00:05, 528.33 examples/s]Processing tokenized train KL daset:  17%|█▋        | 598/3552 [00:01<00:05, 534.14 examples/s]Processing tokenized train KL dataset:  18%|█▊        | 652/3552 [00:01<00:05, 533.80 examples/s]Processing tokenized train KL dataset:  20%|█▉        | 706/3552 [00:01<00:05, 532.12 examples/s]Processing tokenized train KL dataset:  21%|██▏       | 762/3552 [00:01<00:05, 536.98 examples/s]Processing tokenized train KL dataset:  23%|██▎       | 818/3552 [00:01<00:05, 539.19 examples/s]Processing tokenized train KL dataset:  25%|██▌       | 899/3552 [00:01<00:05, 512.27 examples/s]Processing tokenized train KL dataset:  27%|██▋       | 951/3552 [00:01<00:05, 513.68 examples/s]Processing tokenized train KL dataset:  29%|██▉       | 1027/3552 [00:02<00:12, 195.40 examples/s]Processing tokenized train KL dataset:  30%|███       | 1082/3552 [00:02<00:10, 235.05 examples/s]Processing tokenized train KL dataset:  32%|███▏      | 1137/3552 [00:02<00:08, 278.82 examples/s]Processing tokenized train KL dataset:  34%|███▎      | 1190/3552 [00:02<00:07, 319.58 examples/s]Processing tokenized train KL dataset:  35%|███▌      | 1245/3552 [00:03<00:06, 363.11 examples/s]Processing tokenized train KL dataset:  36%|███▋      | 1296/3552 [00:03<00:05, 392.41 examples/s]Processing tokenized train KL dataset:  38%|███▊      | 1349/3552 [00:03<00:05, 421.65 examples/s]Processing tokenized train KL dataset:  39%|███▉      | 1402/3552 [00:03<00:04, 447.41 examples/s]Processing tokenized train KL dataset:  41%|████      | 1456/3552 [00:03<00:04, 468.98 examples/s]Processing tokenized train KL dataset:  43%|████▎     | 1534/3552 [00:03<00:04, 482.75 examples/s]Processing tokenized train KL dataset:  45%|████▍     | 1590/3552 [00:03<00:03, 498.97 examples/s]Processing tokenized train KL dataset:  46%|████▋     | 1644/3552 [00:03<00:03, 507.88 examples/s]Processing tokenized train KL dataset:  48%|████▊     | 1699/35ataset:  16%|█▌        | 563/3552 [00:01<00:05, 525.64 examples/s]Processing tokenized train KL dataset:  17%|█▋        | 616/3552 [00:01<00:05, 523.71 examples/s]Processing tokenized train KL dataset:  20%|█▉        | 696/3552 [00:01<00:05, 523.30 examples/s]Processing tokenized train KL dataset:  21%|██        | 749/3552 [00:01<00:05, 522.58 examples/s]Processing tokenized train KL dataset:  23%|██▎       | 803/3552 [00:01<00:05, 525.34 examples/s]Processing tokenized train KL dataset:  24%|██▍       | 858/3552 [00:01<00:05, 528.42 examples/s]Processing tokenized train KL dataset:  26%|██▌       | 930/3552 [00:01<00:05, 506.15 examples/s]Processing tokenized train KL dataset:  28%|██▊       | 983/3552 [00:01<00:05, 509.72 examples/s]Processing tokenized train KL dataset:  30%|██▉       | 1056/3552 [00:02<00:14, 177.16 examples/s]Processing tokenized train KL dataset:  31%|███▏      | 1113/3552 [00:02<00:11, 218.51 examples/s]Processing tokenize52 [00:03<00:03, 518.84 examples/s]Processing tokenized train KL dataset:  49%|████▉     | 1753/3552 [00:04<00:03, 521.56 examples/s]Processing tokenized train KL dataset:  51%|█████     | 1807/3552 [00:04<00:03, 524.03 examples/s]Processing tokenized train KL dataset:  52%|█████▏    | 1861/3552 [00:04<00:03, 524.84 examples/s]Processing tokenized train KL dataset:  54%|█████▍    | 1916/3552 [00:04<00:03, 529.63 examples/s]Processing tokenized train KL dataset:  56%|█████▌    | 1972/3552 [00:04<00:02, 533.50 examples/s]Processing tokenized train KL dataset:  57%|█████▋    | 2028/3552 [00:05<00:07, 199.40 examples/s]Processing tokenized train KL dataset:  59%|█████▊    | 2083/3552 [00:05<00:05, 245.61 examples/s]Processing tokenized train KL dataset:  60%|██████    | 2137/3552 [00:05<00:04, 291.31 examples/s]Processing tokenized train KL dataset:  62%|██████▏   | 2190/3552 [00:05<00:04, 334.56 exad train KL dataset:  33%|███▎      | 1166/3552 [00:03<00:09, 259.09 examples/s]Processing tokenized train KL dataset:  34%|███▍      | 1220/3552 [00:03<00:07, 303.12 examples/s]Processing tokenized train KL dataset:  36%|███▌      | 1273/3552 [00:03<00:06, 344.54 examples/s]Processing tokenized train KL dataset:  37%|███▋      | 1329/3552 [00:03<00:05, 387.21 examples/s]Processing tokenized train KL dataset:  39%|███▉      | 1380/3552 [00:03<00:05, 413.79 examples/s]Processing tokenized train KL dataset:  40%|████      | 1433/3552 [00:03<00:04, 440.44 examples/s]Processing tokenized train KL dataset:  42%|████▏     | 1486/3552 [00:03<00:04, 461.87 examples/s]Processing tokenized train KL dataset:  43%|████▎     | 1540/3552 [00:03<00:04, 481.26 examples/s]Processing tokenized train KL dataset:  45%|████▍     | 1593/3552 [00:03<00:03, 493.33 examples/s]Processing tokenized train KL dataset:  47%|████▋     | 1672/355mples/s]Processing tokenized train KL dataset:  63%|██████▎   | 2245/3552 [00:05<00:03, 378.06 examples/s]Processing tokenized train KL dataset:  65%|██████▍   | 2300/3552 [00:05<00:03, 414.82 examples/s]Processing tokenized train KL dataset:  66%|██████▋   | 2356/3552 [00:05<00:02, 449.74 examples/s]Processing tokenized train KL dataset:  69%|██████▊   | 2434/3552 [00:05<00:02, 472.20 examples/s]Processing tokenized train KL dataset:  70%|███████   | 2488/3552 [00:05<00:02, 486.34 examples/s]Processing tokenized train KL dataset:  72%|███████▏  | 2544/3552 [00:06<00:01, 504.61 examples/s]Processing tokenized train KL dataset:  73%|███████▎  | 2600/3552 [00:06<00:01, 519.09 examples/s]Processing tokenized train KL dataset:  76%|███████▌  | 2682/3552 [00:06<00:01, 525.96 examples/s]Processing tokenized train KL dataset:  77%|███████▋  | 2736/3552 [00:06<00:01, 525.63 ex2 [00:03<00:03, 504.06 examples/s]Processing tokenized train KL dataset:  49%|████▉     | 1751/3552 [00:04<00:03, 510.22 examples/s]Processing tokenized train KL dataset:  51%|█████     | 1806/3552 [00:04<00:03, 517.20 examples/s]Processing tokenized train KL dataset:  52%|█████▏    | 1860/3552 [00:04<00:03, 519.88 examples/s]Processing tokenized train KL dataset:  54%|█████▍    | 1914/3552 [00:04<00:03, 521.39 examples/s]Processing tokenized train KL dataset:  55%|█████▌    | 1967/3552 [00:04<00:03, 520.38 examples/s]Processing tokenized train KL dataset:  57%|█████▋    | 2026/3552 [00:05<00:07, 204.66 examples/s]Processing tokenized train KL dataset:  59%|█████▊    | 2080/3552 [00:05<00:05, 248.32 examples/s]Processing tokenized train KL dataset:  60%|██████    | 2135/3552 [00:05<00:04, 295.45 examples/s]Processing tokenized train KL dataset:  62%|██████▏   | 2187/3552 [00:05<00:04, 335.98 examples/s]Processing tokenized train KL dataset:  63%|██████▎   | 2241/3552 [00:05<00:03, 376.36 examples/s]Processing tokenized train KL dataset:  65%|██████▍   | 2294/3552 [00:05<00:03, 409.32 examples/s]Processing tokenized train KL dataset:  66%|██████▌   | 2349/3552 [00:05<00:02, 441.90 examples/s]Processing tokenized train KL dataset:  68%|██████▊   | 2428/3552 [00:05<00:02, 467.49 examples/s]Processing tokenized train KL dataset:  70%|██████▉   | 2482/3552 [00:06<00:02, 483.67 examples/s]Processing tokenized train KL dataset:  71%|███████▏  | 2535/3552 [00:06<00:02, 494.25 examples/s]Processing tokenized train KL dataset:  73%|███████▎  | 2589/3552 [00:06<00:01, 504.19 examples/s]Processing tokenized train KL dataset:  74%|███████▍  | 2642/3552 [00:06<00:01, 506.85 examples/s]Processing tokenized train KL dataset:  76%|███████▌  | 2696/3552 [00:06<00:01, 513.06 exaamples/s]Processing tokenized train KL dataset:  79%|███████▉  | 2817/3552 [00:06<00:01, 528.92 examples/s]Processing tokenized train KL dataset:  81%|████████  | 2872/3552 [00:06<00:01, 528.91 examples/s]Processing tokenized train KL dataset:  82%|████████▏ | 2929/3552 [00:06<00:01, 537.13 examples/s]Processing tokenized train KL dataset:  84%|████████▍ | 3000/3552 [00:07<00:02, 218.46 examples/s]Processing tokenized train KL dataset:  86%|████████▌ | 3054/3552 [00:07<00:01, 258.61 examples/s]Processing tokenized train KL dataset:  88%|████████▊ | 3110/3552 [00:07<00:01, 303.97 examples/s]Processing tokenized train KL dataset:  89%|████████▉ | 3164/3552 [00:07<00:01, 344.28 examples/s]Processing tokenized train KL dataset:  91%|█████████ | 3220/3552 [00:07<00:00, 386.58 examples/s]Processing tokenized train KL dataset:  92%|█████████▏| 3275/3552 [00:08<00:00, 421.70 examples/s]Processing tokenized train KL dataset:  94%|█████████▎| 3329/3552 [00:08<00:00, 447.09 examples/s]Processing tokenized train KL dataset:  95%|█████████▌| 3383/3552 [00:08<00:00, 468.24 examples/s]Processing tokenized train KL dataset:  97%|█████████▋| 3436/3552 [00:08<00:00, 481.27 examples/s]Processing tokenized train KL dataset:  98%|█████████▊| 3489/3552 [00:08<00:00, 494.43 examples/s]Processing tokenized train KL dataset: 100%|█████████▉| 3545/3552 [00:08<00:00, 509.53 examples/s]Processing tokenized train KL dataset: 100%|██████████| 3552/3552 [00:08<00:00, 397.84 examples/s]
mples/s]Processing tokenized train KL dataset:  77%|███████▋  | 2750/3552 [00:06<00:01, 516.28 examples/s]Processing tokenized train KL dataset:  79%|███████▉  | 2804/3552 [00:06<00:01, 519.24 examples/s]Processing tokenized train KL dataset:  80%|████████  | 2859/3552 [00:06<00:01, 523.99 examples/s]Processing tokenized train KL dataset:  82%|████████▏ | 2916/3552 [00:06<00:01, 534.62 examples/s]Processing tokenized train KL dataset:  84%|████████▍ | 2996/3552 [00:07<00:01, 532.57 examples/s]Processing tokenized train KL dataset:  86%|████████▌ | 3054/3552 [00:07<00:02, 214.73 examples/s]Processing tokenized train KL dataset:  88%|████████▊ | 3108/3552 [00:07<00:01, 256.54 examples/s]Processing tokenized train KL dataset:  89%|████████▉ | 3163/3552 [00:07<00:01, 301.54 examples/s]Processing tokenized train KL dataset:  91%|█████████ | 3216/3552 [00:08<00:00, 342.14 examples/s]Processing tokenized train KL dataset:  92%|█████████▏| 3268/3552 [00:08<00:00, 376.80 examples/s]Processing tokenized train KL dataset:  94%|█████████▎| 3323/3552 [00:08<00:00, 413.01 examples/s]Processing tokenized train KL dataset:  95%|█████████▌| 3375/3552 [00:08<00:00, 438.04 examples/s]Processing tokenized train KL dataset:  97%|█████████▋| 3429/3552 [00:08<00:00, 462.33 examples/s]Processing tokenized train KL dataset:  98%|█████████▊| 3484/3552 [00:08<00:00, 483.44 examples/s]Processing tokenized train KL dataset: 100%|█████████▉| 3537/3552 [00:08<00:00, 493.49 examples/s]Processing tokenized train KL dataset: 100%|██████████| 3552/3552 [00:09<00:00, 391.79 examples/s]
Filtering desirable examples:   0%|          | 0/3552 [00:00<?, ? examples/s]Filtering desirable examples:  28%|██▊       | 1000/3552 [00:04<00:11, 212.77 examples/s]Filtering desirable examples:  56%|█████▋    | 2000/3552 [00:09<00:07, 213.13 examples/s]Filtering desirable examples:  84%|████████▍ | 3000/3552 [00:14<00:02, 214.25 examples/s]Filtering desirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 215.61 examples/s]Filtering desirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 214.71 examples/s]
Filtering desirable examples:   0%|          | 0/3552 [00:00<?, ? examples/s]Filtering desirable examples:  28%|██▊       | 1000/3552 [00:04<00:12, 212.03 examples/s]Filtering desirable examples:  56%|█████▋    | 2000/3552 [00:09<00:07, 213.62 examples/s]Filtering desirable examples:  84%|████████▍ | 3000/3552 [00:14<00:02, 211.71 examples/s]Filtering desirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 212.31 examples/s]Filtering desirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 212.32 examples/s]
Filtering undesirable examples:   0%|          | 0/3552 [00:00<?, ? examples/s]Filtering undesirable examples:  28%|██▊       | 1000/3552 [00:04<00:11, 213.91 examples/s]Filtering undesirable examples:  56%|█████▋    | 2000/3552 [00:09<00:07, 215.16 examples/s]Filtering undesirable examples:  84%|████████▍ | 3000/3552 [00:14<00:02, 209.32 examples/s]Filtering undesirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 211.92 examples/s]Filtering undesirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 212.01 examples/s]
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:606: UserWarning: 
                        You have different amounts of desirable/positive and undesirable/negative examples but the
                        weights on the desirable and undesirable losses don't seem to be in an ideal range. Based
                        on your data, we recommend EITHER desirable_weight in [1.89, 2.52]
                        or undesirable_weight in [0.4, 0.53] (but NOT BOTH).
                        See the documentation on how to optimally set these weights.
  warnings.warn(
Filtering undesirable examples:   0%|          | 0/3552 [00:00<?, ? examples/s]Filtering undesirable examples:  28%|██▊       | 1000/3552 [00:04<00:11, 214.73 examples/s]Filtering undesirable examples:  56%|█████▋    | 2000/3552 [00:09<00:07, 214.73 examples/s]Filtering undesirable examples:  84%|████████▍ | 3000/3552 [00:14<00:02, 209.23 examples/s]Filtering undesirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 211.84 examples/s]Filtering undesirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 211.96 examples/s]
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:606: UserWarning: 
                        You have different amounts of desirable/positive and undesirable/negative examples but the
                        weights on the desirable and undesirable losses don't seem to be in an ideal range. Based
                        on your data, we recommend EITHER desirable_weight in [1.89, 2.52]
                        or undesirable_weight in [0.4, 0.53] (but NOT BOTH).
                        See the documentation on how to optimally set these weights.
  warnings.warn(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Tokenizing train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Tokenizing train dataset:  28%|██▊       | 1000/3552 [00:02<00:05, 471.90 examples/s]Tokenizing train dataset:  56%|█████▋    | 2000/3552 [00:03<00:02, 551.48 examples/s]Tokenizing train dataset:  84%|████████▍ | 3000/3552 [00:05<00:00, 583.58 examples/s]Tokenizing train dataset: 100%|██████████| 3552/3552 [00:06<00:00, 594.07 examples/s]Tokenizing train dataset: 100%|██████████| 3552/3552 [00:06<00:00, 563.94 examples/s]
Tokenizing train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Tokenizing train dataset:  28%|██▊       | 1000/3552 [00:02<00:06, 403.02 examples/s]Tokenizing train dataset:  56%|█████▋    | 2000/3552 [00:04<00:03, 502.66 examples/s]Tokenizing train dataset:  84%|████████▍ | 3000/3552 [00:05<00:01, 546.22 examples/s]Tokenizing train dataset: 100%|██████████| 3552/3552 [00:06<00:00, 562.99 examples/s]Tokenizing train dataset: 100%|██████████| 3552/3552 [00:06<00:00, 525.68 examples/s]
Extracting KL train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Extracting KL train dataset:   2%|▏         | 68/3552 [00:00<00:05, 650.01 examples/s]Extracting KL train dataset:   4%|▍         | 144/3552 [00:00<00:07, 453.95 examples/s]Extracting KL train dataset:   6%|▌         | 216/3552 [00:00<00:07, 423.15 examples/s]Extracting KL train dataset:   8%|▊         | 288/3552 [00:00<00:06, 492.87 examples/s]Extracting KL train dataset:  10%|█         | 356/3552 [00:00<00:05, 538.74 examples/s]Extracting KL train dataset:  12%|█▏        | 428/3552 [00:00<00:05, 578.48 examples/s]Extracting KL train dataset:  14%|█▍        | 500/3552 [00:00<00:05, 606.04 examples/s]Extracting KL train dataset:  16%|█▌        | 568/3552 [00:01<00:04, 619.68 examples/s]Extracting KL train dataset:  18%|█▊        | 636/3552 [00:01<00:04, 630.41 examples/s]Extracting KL train dataset:  20%|█▉        | 708/3552 [00:01<00:04, 646.34 examples/s]Extracting KL train dataset:  22%|█Extracting KL train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Extracting KL train dataset:   2%|▏         | 72/3552 [00:00<00:09, 370.94 examples/s]Extracting KL train dataset:   4%|▍         | 144/3552 [00:00<00:06, 501.37 examples/s]Extracting KL train dataset:   6%|▌         | 212/3552 [00:00<00:07, 433.54 examples/s]Extracting KL train dataset:   8%|▊         | 284/3552 [00:00<00:06, 503.60 examples/s]Extracting KL train dataset:  10%|█         | 356/3552 [00:00<00:05, 552.84 examples/s]Extracting KL train dataset:  12%|█▏        | 424/3552 [00:00<00:05, 584.01 examples/s]Extracting KL train dataset:  14%|█▍        | 496/3552 [00:00<00:04, 612.47 examples/s]Extracting KL train dataset:  16%|█▌        | 568/3552 [00:01<00:04, 632.34 examples/s]Extracting KL train dataset:  18%|█▊        | 640/3552 [00:01<00:04, 643.13 examples/s]Extracting KL train dataset:  20%|██        | 712/3552 [00:01<00:04, 654.05 examples/s]Extracting KL train dataset:  22%|██▏       | 776/3552 [00:01<00:04, 647.22 examples/s]Extracting KL train dataset:  24%|██▍       | 848/3552 [00:01<00:04, 649.90 examples/s]Extracting KL train dataset:  26%|██▌       | 920/3552 [00:01<00:04, 648.79 examples/s]Extracting KL train dataset:  29%|██▊       | 1020/3552 [00:01<00:03, 653.52 examples/s]Extracting KL train dataset:  31%|███       | 1092/3552 [00:01<00:03, 661.74 examples/s]Extracting KL train dataset:  33%|███▎      | 1164/3552 [00:01<00:03, 653.91 examples/s]Extracting KL train dataset:  35%|███▍      | 1232/3552 [00:02<00:03, 657.63 examples/s]Extracting KL train dataset:  37%|███▋      | 1304/3552 [00:02<00:03, 659.38 examples/s]Extracting KL train dataset:  39%|███▊      | 1372/3552 [00:02<00:03, 655.10 examples/s]Extracting KL train dataset:  41%|████      | 1444/3552 [00:02<00:03, 658.02 examples/s]Extracting KL train dataset:  43%|████▎     | 1512/3552 [00:02<00:03, 660.71 examples/s]Extra█▏       | 784/3552 [00:01<00:04, 659.23 examples/s]Extracting KL train dataset:  24%|██▍       | 860/3552 [00:01<00:04, 669.31 examples/s]Extracting KL train dataset:  26%|██▌       | 928/3552 [00:01<00:03, 668.95 examples/s]Extracting KL train dataset:  28%|██▊       | 1000/3552 [00:01<00:03, 671.78 examples/s]Extracting KL train dataset:  30%|███       | 1072/3552 [00:01<00:03, 674.16 examples/s]Extracting KL train dataset:  32%|███▏      | 1140/3552 [00:01<00:03, 672.82 examples/s]Extracting KL train dataset:  34%|███▍      | 1208/3552 [00:01<00:03, 669.81 examples/s]Extracting KL train dataset:  36%|███▌      | 1280/3552 [00:02<00:03, 675.75 examples/s]Extracting KL train dataset:  38%|███▊      | 1352/3552 [00:02<00:03, 679.75 examples/s]Extracting KL train dataset:  41%|████      | 1456/3552 [00:02<00:03, 675.38 examples/s]Extracting KL train dataset:  43%|████▎     | 1528/3552 [00:02<00:02, 674.84 examples/s]Extracting KL train dataset:  44%|████▍     | 1580/3552 [00:02<00:02, 660.03 examples/s]Extracting KL train dataset:  47%|████▋     | 1652/3552 [00:02<00:02, 662.43 examples/s]Extracting KL train dataset:  49%|████▊     | 1724/3552 [00:02<00:02, 662.60 examples/s]Extracting KL train dataset:  50%|█████     | 1792/3552 [00:02<00:02, 659.86 examples/s]Extracting KL train dataset:  52%|█████▏    | 1860/3552 [00:02<00:02, 660.00 examples/s]Extracting KL train dataset:  54%|█████▍    | 1932/3552 [00:03<00:02, 660.33 examples/s]Extracting KL train dataset:  56%|█████▋    | 2000/3552 [00:03<00:02, 660.36 examples/s]Extracting KL train dataset:  58%|█████▊    | 2068/3552 [00:03<00:02, 657.23 examples/s]Extracting KL train dataset:  60%|██████    | 2140/3552 [00:03<00:02, 662.22 examples/s]Extracting KL train dataset:  62%|██████▏   | 2208/3552 [00:03<00:02, 664.32 examples/s]Extracting KL train datascting KL train dataset:  45%|████▌     | 1600/3552 [00:02<00:02, 676.69 examples/s]Extracting KL train dataset:  47%|████▋     | 1672/3552 [00:02<00:02, 676.66 examples/s]Extracting KL train dataset:  49%|████▉     | 1744/3552 [00:02<00:02, 680.98 examples/s]Extracting KL train dataset:  52%|█████▏    | 1848/3552 [00:02<00:02, 678.36 examples/s]Extracting KL train dataset:  54%|█████▍    | 1920/3552 [00:03<00:02, 680.67 examples/s]Extracting KL train dataset:  56%|█████▌    | 1992/3552 [00:03<00:02, 677.90 examples/s]Extracting KL train dataset:  58%|█████▊    | 2064/3552 [00:03<00:02, 677.62 examples/s]Extracting KL train dataset:  60%|██████    | 2136/3552 [00:03<00:02, 674.89 examples/s]Extracting KL train dataset:  62%|██████▏   | 2208/3552 [00:03<00:01, 679.33 examples/s]Extracting KL train dataset:  64%|██████▍   | 2280/3552 [00:03<00:01, 678.14 examples/s]Extracting KL train det:  64%|██████▍   | 2280/3552 [00:03<00:01, 662.37 examples/s]Extracting KL train dataset:  66%|██████▌   | 2352/3552 [00:03<00:01, 657.41 examples/s]Extracting KL train dataset:  68%|██████▊   | 2424/3552 [00:03<00:01, 656.52 examples/s]Extracting KL train dataset:  70%|███████   | 2492/3552 [00:03<00:01, 651.72 examples/s]Extracting KL train dataset:  72%|███████▏  | 2564/3552 [00:04<00:01, 655.71 examples/s]Extracting KL train dataset:  74%|███████▍  | 2636/3552 [00:04<00:01, 655.13 examples/s]Extracting KL train dataset:  76%|███████▌  | 2704/3552 [00:04<00:01, 652.80 examples/s]Extracting KL train dataset:  78%|███████▊  | 2772/3552 [00:04<00:01, 653.00 examples/s]Extracting KL train dataset:  80%|████████  | 2844/3552 [00:04<00:01, 657.56 examples/s]Extracting KL train dataset:  82%|████████▏ | 2912/3552 [00:04<00:00, 653.87 examples/s]Extraataset:  66%|██████▌   | 2352/3552 [00:03<00:01, 680.68 examples/s]Extracting KL train dataset:  68%|██████▊   | 2424/3552 [00:03<00:01, 674.38 examples/s]Extracting KL train dataset:  70%|███████   | 2496/3552 [00:03<00:01, 675.12 examples/s]Extracting KL train dataset:  72%|███████▏  | 2568/3552 [00:03<00:01, 673.72 examples/s]Extracting KL train dataset:  74%|███████▍  | 2640/3552 [00:04<00:01, 671.32 examples/s]Extracting KL train dataset:  76%|███████▌  | 2708/3552 [00:04<00:01, 671.69 examples/s]Extracting KL train dataset:  78%|███████▊  | 2780/3552 [00:04<00:01, 677.35 examples/s]Extracting KL train dataset:  80%|████████  | 2848/3552 [00:04<00:01, 671.79 examples/s]Extracting KL train dataset:  82%|████████▏ | 2916/3552 [00:04<00:00, 665.59 examples/s]Extracting KL train dataset:  84%|████████▍ | 2988/3552 [00:04<00:00, 674.12 examples/cting KL train dataset:  84%|████████▍ | 2984/3552 [00:04<00:00, 656.13 examples/s]Extracting KL train dataset:  86%|████████▌ | 3052/3552 [00:04<00:00, 652.97 examples/s]Extracting KL train dataset:  88%|████████▊ | 3124/3552 [00:04<00:00, 658.11 examples/s]Extracting KL train dataset:  90%|████████▉ | 3192/3552 [00:05<00:00, 657.06 examples/s]Extracting KL train dataset:  92%|█████████▏| 3264/3552 [00:05<00:00, 656.92 examples/s]Extracting KL train dataset:  94%|█████████▍| 3336/3552 [00:05<00:00, 656.35 examples/s]Extracting KL train dataset:  96%|█████████▌| 3404/3552 [00:05<00:00, 653.60 examples/s]Extracting KL train dataset:  98%|█████████▊| 3476/3552 [00:05<00:00, 657.69 examples/s]Extracting KL train dataset: 100%|█████████▉| 3548/3552 [00:05<00:00, 657.62 examples/s]Extracting KL train dataset: 100%|██████████| 3552/3552 [00:05<00:00, 634.82 examples/s]
s]Extracting KL train dataset:  86%|████████▌ | 3060/3552 [00:04<00:00, 671.46 examples/s]Extracting KL train dataset:  88%|████████▊ | 3132/3552 [00:04<00:00, 670.10 examples/s]Extracting KL train dataset:  90%|█████████ | 3200/3552 [00:04<00:00, 666.51 examples/s]Extracting KL train dataset:  92%|█████████▏| 3268/3552 [00:05<00:00, 660.92 examples/s]Extracting KL train dataset:  94%|█████████▍| 3344/3552 [00:05<00:00, 672.10 examples/s]Extracting KL train dataset:  96%|█████████▌| 3416/3552 [00:05<00:00, 675.79 examples/s]Extracting KL train dataset:  98%|█████████▊| 3484/3552 [00:05<00:00, 672.84 examples/s]Extracting KL train dataset: 100%|██████████| 3552/3552 [00:05<00:00, 674.60 examples/s]Extracting KL train dataset: 100%|██████████| 3552/3552 [00:05<00:00, 647.21 examples/s]
Processing tokenized train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Processing tokenized train dataset:   1%|▏         | 53/3552 [00:00<00:06, 515.48 examples/s]Processing tokenized train dataset:   3%|▎         | 107/3552 [00:00<00:06, 526.50 examples/s]Processing tokenized train dataset:   5%|▌         | 187/3552 [00:00<00:06, 528.03 examples/s]Processing tokenized train dataset:   7%|▋         | 241/3552 [00:00<00:06, 528.25 examples/s]Processing tokenized train dataset:   8%|▊         | 294/3552 [00:00<00:06, 524.03 examples/s]Processing tokenized train dataset:  10%|█         | 372/3552 [00:00<00:06, 519.39 examples/s]Processing tokenized train dataset:  12%|█▏        | 425/3552 [00:00<00:06, 519.90 examples/s]Processing tokenized train dataset:  13%|█▎        | 478/3552 [00:00<00:05, 520.29 examples/s]Processing tokenized train dataset:  16%|█▌        | 556/3552 [00:01<00:05, 514.50 examples/s]Processing tokenized train dataset:  18%|█▊        | 632/Processing tokenized train dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Processing tokenized train dataset:   2%|▏         | 55/3552 [00:00<00:06, 537.16 examples/s]Processing tokenized train dataset:   3%|▎         | 110/3552 [00:00<00:06, 533.83 examples/s]Processing tokenized train dataset:   5%|▍         | 166/3552 [00:00<00:06, 539.80 examples/s]Processing tokenized train dataset:   6%|▋         | 223/3552 [00:00<00:06, 544.82 examples/s]Processing tokenized train dataset:   9%|▊         | 305/3552 [00:00<00:05, 543.48 examples/s]Processing tokenized train dataset:  10%|█         | 361/3552 [00:00<00:05, 543.62 examples/s]Processing tokenized train dataset:  12%|█▏        | 442/3552 [00:00<00:05, 536.81 examples/s]Processing tokenized train dataset:  14%|█▍        | 497/3552 [00:00<00:05, 539.90 examples/s]Processing tokenized train dataset:  16%|█▌        | 577/3552 [00:01<00:05, 536.57 examples/s]Processing tokenized train dataset:  18%|█▊        | 656/3552 [00:01<00:05, 509.94 examples/s]Processing tokenized train dataset:  19%|█▉        | 684/3552 [00:01<00:05, 510.45 examples/s]Processing tokenized train dataset:  21%|██        | 736/3552 [00:01<00:05, 511.46 examples/s]Processing tokenized train dataset:  23%|██▎       | 812/3552 [00:01<00:05, 506.43 examples/s]Processing tokenized train dataset:  25%|██▍       | 886/3552 [00:01<00:05, 500.03 examples/s]Processing tokenized train dataset:  26%|██▋       | 938/3552 [00:01<00:05, 502.46 examples/s]Processing tokenized train dataset:  28%|██▊       | 989/3552 [00:01<00:05, 501.53 examples/s]Processing tokenized train dataset:  30%|██▉       | 1056/3552 [00:03<00:18, 133.85 examples/s]Processing tokenized train dataset:  31%|███       | 1108/3552 [00:03<00:14, 166.72 examples/s]Processing tokenized train dataset:  33%|███▎      | 1160/3552 [00:03<00:11, 204.73 examples/s]Processing tokenized train dataset:  34%|███▍      | 1212/3552 [00:03552 [00:01<00:05, 531.54 examples/s]Processing tokenized train dataset:  20%|██        | 711/3552 [00:01<00:05, 532.17 examples/s]Processing tokenized train dataset:  22%|██▏       | 765/3552 [00:01<00:05, 532.50 examples/s]Processing tokenized train dataset:  23%|██▎       | 821/3552 [00:01<00:05, 536.35 examples/s]Processing tokenized train dataset:  25%|██▍       | 877/3552 [00:01<00:04, 535.47 examples/s]Processing tokenized train dataset:  26%|██▌       | 931/3552 [00:01<00:04, 534.82 examples/s]Processing tokenized train dataset:  28%|██▊       | 1000/3552 [00:02<00:18, 134.35 examples/s]Processing tokenized train dataset:  30%|██▉       | 1057/3552 [00:03<00:14, 171.58 examples/s]Processing tokenized train dataset:  31%|███▏      | 1114/3552 [00:03<00:11, 214.47 examples/s]Processing tokenized train dataset:  33%|███▎      | 1171/3552 [00:03<00:09, 261.38 examples/s]Processing tokenized train dataset:  34%|███▍      | 1225/3552 3<00:09, 246.43 examples/s]Processing tokenized train dataset:  36%|███▌      | 1267/3552 [00:03<00:07, 294.61 examples/s]Processing tokenized train dataset:  37%|███▋      | 1319/3552 [00:03<00:06, 335.25 examples/s]Processing tokenized train dataset:  39%|███▊      | 1371/3552 [00:03<00:05, 371.30 examples/s]Processing tokenized train dataset:  40%|████      | 1425/3552 [00:03<00:05, 408.88 examples/s]Processing tokenized train dataset:  42%|████▏     | 1476/3552 [00:04<00:04, 432.76 examples/s]Processing tokenized train dataset:  43%|████▎     | 1530/3552 [00:04<00:04, 459.06 examples/s]Processing tokenized train dataset:  45%|████▌     | 1608/3552 [00:04<00:04, 478.37 examples/s]Processing tokenized train dataset:  47%|████▋     | 1660/3552 [00:04<00:03, 486.95 examples/s]Processing tokenized train dataset:  48%|████▊     | 1713/3552 [00:04<00:03, 496.90 examples/s]Processing tokenized train dataset:  50%|███[00:03<00:07, 305.83 examples/s]Processing tokenized train dataset:  36%|███▌      | 1282/3552 [00:03<00:06, 353.76 examples/s]Processing tokenized train dataset:  38%|███▊      | 1339/3552 [00:03<00:05, 397.51 examples/s]Processing tokenized train dataset:  39%|███▉      | 1396/3552 [00:03<00:04, 433.72 examples/s]Processing tokenized train dataset:  41%|████      | 1452/3552 [00:03<00:04, 461.08 examples/s]Processing tokenized train dataset:  42%|████▏     | 1507/3552 [00:03<00:04, 481.66 examples/s]Processing tokenized train dataset:  45%|████▍     | 1588/3552 [00:04<00:03, 499.04 examples/s]Processing tokenized train dataset:  46%|████▌     | 1642/3552 [00:04<00:03, 506.61 examples/s]Processing tokenized train dataset:  48%|████▊     | 1698/3552 [00:04<00:03, 517.67 examples/s]Processing tokenized train dataset:  50%|█████     | 1777/3552 [00:04<00:03, 518.66 examples/s]Processing tokenized train dataset:  52%|███     | 1789/3552 [00:04<00:03, 498.75 examples/s]Processing tokenized train dataset:  52%|█████▏    | 1841/3552 [00:04<00:03, 500.99 examples/s]Processing tokenized train dataset:  54%|█████▍    | 1918/3552 [00:04<00:03, 501.26 examples/s]Processing tokenized train dataset:  55%|█████▌    | 1970/3552 [00:04<00:03, 504.75 examples/s]Processing tokenized train dataset:  57%|█████▋    | 2028/3552 [00:05<00:09, 154.66 examples/s]Processing tokenized train dataset:  59%|█████▊    | 2081/3552 [00:06<00:07, 191.57 examples/s]Processing tokenized train dataset:  60%|██████    | 2135/3552 [00:06<00:06, 234.07 examples/s]Processing tokenized train dataset:  62%|██████▏   | 2191/3552 [00:06<00:04, 282.22 examples/s]Processing tokenized train dataset:  63%|██████▎   | 2242/3552 [00:06<00:04, 322.04 examples/s]Processing tokenized train dataset:  65%|██████▍   | 2294/3552 [00:06<00:03, 360.12 ex███▏    | 1831/3552 [00:04<00:03, 521.13 examples/s]Processing tokenized train dataset:  53%|█████▎    | 1886/3552 [00:04<00:03, 527.33 examples/s]Processing tokenized train dataset:  55%|█████▌    | 1967/3552 [00:04<00:03, 527.92 examples/s]Processing tokenized train dataset:  57%|█████▋    | 2027/3552 [00:05<00:09, 162.71 examples/s]Processing tokenized train dataset:  59%|█████▊    | 2085/3552 [00:05<00:07, 203.09 examples/s]Processing tokenized train dataset:  60%|██████    | 2139/3552 [00:06<00:05, 243.63 examples/s]Processing tokenized train dataset:  62%|██████▏   | 2195/3552 [00:06<00:04, 289.37 examples/s]Processing tokenized train dataset:  63%|██████▎   | 2252/3552 [00:06<00:03, 337.30 examples/s]Processing tokenized train dataset:  65%|██████▍   | 2308/3552 [00:06<00:03, 379.35 examples/s]Processing tokenized train dataset:  67%|██████▋   | 2364/3552 [00:06<00:02, amples/s]Processing tokenized train dataset:  66%|██████▌   | 2349/3552 [00:06<00:03, 398.87 examples/s]Processing tokenized train dataset:  68%|██████▊   | 2401/3552 [00:06<00:02, 426.98 examples/s]Processing tokenized train dataset:  69%|██████▉   | 2454/3552 [00:06<00:02, 448.98 examples/s]Processing tokenized train dataset:  71%|███████   | 2507/3552 [00:06<00:02, 468.90 examples/s]Processing tokenized train dataset:  72%|███████▏  | 2561/3552 [00:06<00:02, 486.32 examples/s]Processing tokenized train dataset:  74%|███████▎  | 2615/3552 [00:07<00:01, 497.53 examples/s]Processing tokenized train dataset:  76%|███████▌  | 2693/3552 [00:07<00:01, 501.30 examples/s]Processing tokenized train dataset:  78%|███████▊  | 2771/3552 [00:07<00:01, 504.22 examples/s]Processing tokenized train dataset:  79%|███████▉  | 2823/3552 [00:07<00:01, 506.04 examples/s]Processing tok416.73 examples/s]Processing tokenized train dataset:  68%|██████▊   | 2418/3552 [00:06<00:02, 442.88 examples/s]Processing tokenized train dataset:  70%|██████▉   | 2472/3552 [00:06<00:02, 466.50 examples/s]Processing tokenized train dataset:  71%|███████   | 2528/3552 [00:06<00:02, 488.61 examples/s]Processing tokenized train dataset:  73%|███████▎  | 2582/3552 [00:06<00:01, 499.44 examples/s]Processing tokenized train dataset:  75%|███████▍  | 2662/3552 [00:06<00:01, 508.21 examples/s]Processing tokenized train dataset:  77%|███████▋  | 2744/3552 [00:07<00:01, 519.29 examples/s]Processing tokenized train dataset:  79%|███████▉  | 2798/3552 [00:07<00:01, 523.16 examples/s]Processing tokenized train dataset:  81%|████████  | 2877/3552 [00:07<00:01, 521.77 examples/s]Processing tokenized train dataset:  83%|████████▎ | 2958/3552 [00:07<00:01, 524.87 examples/s]Penized train dataset:  81%|████████  | 2876/3552 [00:07<00:01, 510.08 examples/s]Processing tokenized train dataset:  83%|████████▎ | 2955/3552 [00:07<00:01, 510.88 examples/s]Processing tokenized train dataset:  85%|████████▌ | 3027/3552 [00:08<00:03, 170.56 examples/s]Processing tokenized train dataset:  87%|████████▋ | 3079/3552 [00:08<00:02, 204.61 examples/s]Processing tokenized train dataset:  88%|████████▊ | 3131/3552 [00:08<00:01, 242.74 examples/s]Processing tokenized train dataset:  90%|████████▉ | 3184/3552 [00:09<00:01, 284.76 examples/s]Processing tokenized train dataset:  91%|█████████ | 3233/3552 [00:09<00:00, 319.79 examples/s]Processing tokenized train dataset:  93%|█████████▎| 3286/3552 [00:09<00:00, 359.49 examples/s]Processing tokenized train dataset:  94%|█████████▍| 3338/3552 [00:09<00:00, 394.52 examples/s]Processingrocessing tokenized train dataset:  85%|████████▌ | 3028/3552 [00:08<00:02, 177.60 examples/s]Processing tokenized train dataset:  87%|████████▋ | 3084/3552 [00:08<00:02, 214.02 examples/s]Processing tokenized train dataset:  88%|████████▊ | 3138/3552 [00:08<00:01, 252.78 examples/s]Processing tokenized train dataset:  90%|████████▉ | 3192/3552 [00:08<00:01, 292.51 examples/s]Processing tokenized train dataset:  91%|█████████▏| 3246/3552 [00:08<00:00, 334.06 examples/s]Processing tokenized train dataset:  93%|█████████▎| 3301/3552 [00:09<00:00, 375.45 examples/s]Processing tokenized train dataset:  95%|█████████▍| 3360/3552 [00:09<00:00, 420.14 examples/s]Processing tokenized train dataset:  96%|█████████▌| 3415/3552 [00:09<00:00, 449.80 examples/s]Processing tokenized train dataset:  98%|█████████▊| 3471/3552 [00:09<00:00, 474.37 e tokenized train dataset:  95%|█████████▌| 3390/3552 [00:09<00:00, 421.83 examples/s]Processing tokenized train dataset:  97%|█████████▋| 3444/3552 [00:09<00:00, 449.77 examples/s]Processing tokenized train dataset:  98%|█████████▊| 3496/3552 [00:09<00:00, 467.16 examples/s]Processing tokenized train dataset: 100%|█████████▉| 3549/3552 [00:09<00:00, 479.79 examples/s]Processing tokenized train dataset: 100%|██████████| 3552/3552 [00:10<00:00, 343.09 examples/s]
xamples/s]Processing tokenized train dataset:  99%|█████████▉| 3529/3552 [00:09<00:00, 498.21 examples/s]Processing tokenized train dataset: 100%|██████████| 3552/3552 [00:10<00:00, 352.41 examples/s]
Processing tokenized train KL dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Processing tokenized train KL dataset:   1%|▏         | 53/3552 [00:00<00:06, 513.08 examples/s]Processing tokenized train KL dataset:   3%|▎         | 106/3552 [00:00<00:06, 516.73 examples/s]Processing tokenized train KL dataset:   4%|▍         | 159/3552 [00:00<00:06, 514.38 examples/s]Processing tokenized train KL dataset:   6%|▌         | 213/3552 [00:00<00:06, 520.08 examples/s]Processing tokenized train KL dataset:   7%|▋         | 266/3552 [00:00<00:06, 518.01 examples/s]Processing tokenized train KL dataset:   9%|▉         | 318/3552 [00:00<00:06, 515.51 examples/s]Processing tokenized train KL dataset:  11%|█         | 395/3552 [00:00<00:06, 512.27 examples/s]Processing tokenized train KL dataset:  13%|█▎        | 447/3552 [00:00<00:06, 512.37 examples/s]Processing tokenized train KL dataset:  14%|█▍        | 501/3552 [00:00<00:05, 515.66 examples/s]Processing tokenized train KL datProcessing tokenized train KL dataset:   0%|          | 0/3552 [00:00<?, ? examples/s]Processing tokenized train KL dataset:   2%|▏         | 54/3552 [00:00<00:06, 527.35 examples/s]Processing tokenized train KL dataset:   3%|▎         | 107/3552 [00:00<00:06, 522.25 examples/s]Processing tokenized train KL dataset:   5%|▍         | 163/3552 [00:00<00:06, 533.05 examples/s]Processing tokenized train KL dataset:   7%|▋         | 243/3552 [00:00<00:06, 530.84 examples/s]Processing tokenized train KL dataset:   8%|▊         | 297/3552 [00:00<00:06, 531.32 examples/s]Processing tokenized train KL dataset:  10%|▉         | 351/3552 [00:00<00:06, 531.65 examples/s]Processing tokenized train KL dataset:  11%|█▏        | 406/3552 [00:00<00:05, 532.23 examples/s]Processing tokenized train KL dataset:  13%|█▎        | 460/3552 [00:00<00:05, 532.25 examples/s]Processing tokenized train KL dataset:  14%|█▍        | 515/3552 [00:00<00:05, 535.64 examples/s]Processing tokenized train KL daset:  16%|█▋        | 579/3552 [00:01<00:05, 512.54 examples/s]Processing tokenized train KL dataset:  18%|█▊        | 632/3552 [00:01<00:05, 513.92 examples/s]Processing tokenized train KL dataset:  19%|█▉        | 685/3552 [00:01<00:05, 515.26 examples/s]Processing tokenized train KL dataset:  21%|██        | 738/3552 [00:01<00:05, 516.78 examples/s]Processing tokenized train KL dataset:  23%|██▎       | 814/3552 [00:01<00:05, 510.03 examples/s]Processing tokenized train KL dataset:  25%|██▌       | 890/3552 [00:01<00:05, 506.39 examples/s]Processing tokenized train KL dataset:  27%|██▋       | 959/3552 [00:01<00:05, 486.95 examples/s]Processing tokenized train KL dataset:  29%|██▉       | 1028/3552 [00:02<00:13, 187.11 examples/s]Processing tokenized train KL dataset:  30%|███       | 1083/3552 [00:02<00:10, 225.04 examples/s]Processing tokenized train KL dataset:  32%|███▏      | 1136/3552 [00:02<00:09, 264.14 examples/s]Processing tokenizedataset:  16%|█▌        | 569/3552 [00:01<00:05, 534.84 examples/s]Processing tokenized train KL dataset:  18%|█▊        | 623/3552 [00:01<00:05, 531.57 examples/s]Processing tokenized train KL dataset:  19%|█▉        | 677/3552 [00:01<00:05, 530.91 examples/s]Processing tokenized train KL dataset:  21%|██        | 732/3552 [00:01<00:05, 533.96 examples/s]Processing tokenized train KL dataset:  23%|██▎       | 814/3552 [00:01<00:05, 533.40 examples/s]Processing tokenized train KL dataset:  24%|██▍       | 870/3552 [00:01<00:05, 536.09 examples/s]Processing tokenized train KL dataset:  26%|██▋       | 940/3552 [00:01<00:05, 509.62 examples/s]Processing tokenized train KL dataset:  28%|██▊       | 996/3552 [00:01<00:04, 519.27 examples/s]Processing tokenized train KL dataset:  30%|██▉       | 1055/3552 [00:02<00:15, 159.47 examples/s]Processing tokenized train KL dataset:  31%|███▏      | 1112/3552 [00:02<00:12, 200.82 examples/s]Processing tokenize train KL dataset:  33%|███▎      | 1186/3552 [00:03<00:07, 300.93 examples/s]Processing tokenized train KL dataset:  35%|███▍      | 1240/3552 [00:03<00:06, 343.15 examples/s]Processing tokenized train KL dataset:  36%|███▋      | 1293/3552 [00:03<00:05, 379.70 examples/s]Processing tokenized train KL dataset:  38%|███▊      | 1345/3552 [00:03<00:05, 410.84 examples/s]Processing tokenized train KL dataset:  39%|███▉      | 1398/3552 [00:03<00:04, 435.56 examples/s]Processing tokenized train KL dataset:  41%|████      | 1451/3552 [00:03<00:04, 456.12 examples/s]Processing tokenized train KL dataset:  42%|████▏     | 1504/3552 [00:03<00:04, 473.10 examples/s]Processing tokenized train KL dataset:  44%|████▍     | 1557/3552 [00:03<00:04, 484.61 examples/s]Processing tokenized train KL dataset:  45%|████▌     | 1610/3552 [00:03<00:03, 492.92 examples/s]Processing tokenized train KL dataset:  47%|████▋     | 1664/3552d train KL dataset:  33%|███▎      | 1164/3552 [00:03<00:09, 240.93 examples/s]Processing tokenized train KL dataset:  34%|███▍      | 1220/3552 [00:03<00:08, 288.54 examples/s]Processing tokenized train KL dataset:  36%|███▌      | 1275/3552 [00:03<00:06, 333.98 examples/s]Processing tokenized train KL dataset:  37%|███▋      | 1331/3552 [00:03<00:05, 377.94 examples/s]Processing tokenized train KL dataset:  39%|███▉      | 1387/3552 [00:03<00:05, 415.94 examples/s]Processing tokenized train KL dataset:  41%|████      | 1442/3552 [00:03<00:04, 445.29 examples/s]Processing tokenized train KL dataset:  42%|████▏     | 1495/3552 [00:03<00:04, 465.36 examples/s]Processing tokenized train KL dataset:  44%|████▎     | 1549/3552 [00:03<00:04, 481.91 examples/s]Processing tokenized train KL dataset:  45%|████▌     | 1603/3552 [00:03<00:03, 496.44 examples/s]Processing tokenized train KL dataset:  47%|████▋     | 1658/3552 [00:03<00:03, 508.05 examples/s]Processing tokenized train KL dataset:  48%|████▊     | 1714/3552 [00:04<00:03, 521.23 examples/s]Processing tokenized train KL dataset:  51%|█████     | 1796/3552 [00:04<00:03, 525.52 examples/s]Processing tokenized train KL dataset:  52%|█████▏    | 1850/3552 [00:04<00:03, 528.96 examples/s]Processing tokenized train KL dataset:  54%|█████▎    | 1906/3552 [00:04<00:03, 532.51 examples/s]Processing tokenized train KL dataset:  55%|█████▌    | 1960/3552 [00:04<00:02, 532.25 examples/s]Processing tokenized train KL dataset:  57%|█████▋    | 2027/3552 [00:05<00:07, 211.98 examples/s]Processing tokenized train KL dataset:  59%|█████▊    | 2083/3552 [00:05<00:05, 257.22 examples/s]Processing tokenized train KL dataset:  60%|██████    | 2135/3552 [00:05<00:04, 298.40 examples/s]Processing tokenized train KL dataset:  62%|██████▏   | 2190/3552 [00:05<00:03, 342.39 exam [00:04<00:03, 503.81 examples/s]Processing tokenized train KL dataset:  48%|████▊     | 1717/3552 [00:04<00:03, 508.48 examples/s]Processing tokenized train KL dataset:  51%|█████     | 1795/3552 [00:04<00:03, 508.79 examples/s]Processing tokenized train KL dataset:  52%|█████▏    | 1847/3552 [00:04<00:03, 510.01 examples/s]Processing tokenized train KL dataset:  54%|█████▍    | 1926/3552 [00:04<00:03, 511.82 examples/s]Processing tokenized train KL dataset:  56%|█████▋    | 2000/3552 [00:05<00:07, 220.45 examples/s]Processing tokenized train KL dataset:  58%|█████▊    | 2053/3552 [00:05<00:05, 257.59 examples/s]Processing tokenized train KL dataset:  59%|█████▉    | 2105/3552 [00:05<00:04, 296.37 examples/s]Processing tokenized train KL dataset:  61%|██████    | 2159/3552 [00:05<00:04, 338.16 examples/s]Processing tokenized train KL dataset:  62%|██████▏   | 2212/3552 [00:05<00:03, 374.63 exampples/s]Processing tokenized train KL dataset:  63%|██████▎   | 2246/3552 [00:05<00:03, 384.69 examples/s]Processing tokenized train KL dataset:  65%|██████▍   | 2300/3552 [00:05<00:02, 418.79 examples/s]Processing tokenized train KL dataset:  66%|██████▋   | 2356/3552 [00:05<00:02, 450.00 examples/s]Processing tokenized train KL dataset:  69%|██████▊   | 2434/3552 [00:06<00:02, 469.57 examples/s]Processing tokenized train KL dataset:  70%|███████   | 2488/3552 [00:06<00:02, 484.65 examples/s]Processing tokenized train KL dataset:  72%|███████▏  | 2542/3552 [00:06<00:02, 497.14 examples/s]Processing tokenized train KL dataset:  73%|███████▎  | 2597/3552 [00:06<00:01, 508.89 examples/s]Processing tokenized train KL dataset:  75%|███████▍  | 2650/3552 [00:06<00:01, 511.36 examples/s]Processing tokenized train KL dataset:  76%|███████▌  | 2705/3552 [00:06<00:01, 521.49 exales/s]Processing tokenized train KL dataset:  64%|██████▍   | 2265/3552 [00:05<00:03, 406.36 examples/s]Processing tokenized train KL dataset:  65%|██████▌   | 2318/3552 [00:05<00:02, 432.72 examples/s]Processing tokenized train KL dataset:  67%|██████▋   | 2371/3552 [00:05<00:02, 446.51 examples/s]Processing tokenized train KL dataset:  68%|██████▊   | 2425/3552 [00:06<00:02, 468.26 examples/s]Processing tokenized train KL dataset:  70%|██████▉   | 2478/3552 [00:06<00:02, 482.32 examples/s]Processing tokenized train KL dataset:  71%|███████▏  | 2532/3552 [00:06<00:02, 493.97 examples/s]Processing tokenized train KL dataset:  73%|███████▎  | 2586/3552 [00:06<00:01, 503.47 examples/s]Processing tokenized train KL dataset:  75%|███████▌  | 2664/3552 [00:06<00:01, 507.42 examples/s]Processing tokenized train KL dataset:  77%|███████▋  | 2741/3552 [00:06<00:01, 506.32 exammples/s]Processing tokenized train KL dataset:  78%|███████▊  | 2759/3552 [00:06<00:01, 525.85 examples/s]Processing tokenized train KL dataset:  80%|███████▉  | 2837/3552 [00:06<00:01, 523.03 examples/s]Processing tokenized train KL dataset:  81%|████████▏ | 2891/3552 [00:06<00:01, 524.34 examples/s]Processing tokenized train KL dataset:  83%|████████▎ | 2946/3552 [00:06<00:01, 528.24 examples/s]Processing tokenized train KL dataset:  84%|████████▍ | 3000/3552 [00:07<00:02, 202.59 examples/s]Processing tokenized train KL dataset:  86%|████████▌ | 3054/3552 [00:07<00:02, 246.78 examples/s]Processing tokenized train KL dataset:  88%|████████▊ | 3108/3552 [00:07<00:01, 292.15 examples/s]Processing tokenized train KL dataset:  89%|████████▉ | 3161/3552 [00:07<00:01, 334.89 examples/s]Processing tokenized train KL dataset:  91%|█████████ | 3215/3552ples/s]Processing tokenized train KL dataset:  79%|███████▊  | 2795/3552 [00:06<00:01, 512.86 examples/s]Processing tokenized train KL dataset:  80%|████████  | 2847/3552 [00:06<00:01, 514.54 examples/s]Processing tokenized train KL dataset:  82%|████████▏ | 2899/3552 [00:06<00:01, 513.96 examples/s]Processing tokenized train KL dataset:  83%|████████▎ | 2952/3552 [00:07<00:01, 516.74 examples/s]Processing tokenized train KL dataset:  85%|████████▌ | 3027/3552 [00:07<00:02, 213.27 examples/s]Processing tokenized train KL dataset:  87%|████████▋ | 3079/3552 [00:07<00:01, 252.36 examples/s]Processing tokenized train KL dataset:  88%|████████▊ | 3132/3552 [00:07<00:01, 294.92 examples/s]Processing tokenized train KL dataset:  90%|████████▉ | 3184/3552 [00:08<00:01, 334.30 examples/s]Processing tokenized train KL dataset:  91%|█████████ | 3237/3552  [00:08<00:00, 377.20 examples/s]Processing tokenized train KL dataset:  92%|█████████▏| 3266/3552 [00:08<00:00, 405.51 examples/s]Processing tokenized train KL dataset:  94%|█████████▎| 3322/3552 [00:08<00:00, 440.56 examples/s]Processing tokenized train KL dataset:  95%|█████████▌| 3378/3552 [00:08<00:00, 468.78 examples/s]Processing tokenized train KL dataset:  97%|█████████▋| 3433/3552 [00:08<00:00, 487.71 examples/s]Processing tokenized train KL dataset:  98%|█████████▊| 3487/3552 [00:08<00:00, 498.58 examples/s]Processing tokenized train KL dataset: 100%|█████████▉| 3543/3552 [00:08<00:00, 514.25 examples/s]Processing tokenized train KL dataset: 100%|██████████| 3552/3552 [00:09<00:00, 390.18 examples/s]
[00:08<00:00, 372.34 examples/s]Processing tokenized train KL dataset:  93%|█████████▎| 3290/3552 [00:08<00:00, 406.36 examples/s]Processing tokenized train KL dataset:  94%|█████████▍| 3343/3552 [00:08<00:00, 435.11 examples/s]Processing tokenized train KL dataset:  96%|█████████▌| 3395/3552 [00:08<00:00, 453.35 examples/s]Processing tokenized train KL dataset:  97%|█████████▋| 3449/3552 [00:08<00:00, 474.91 examples/s]Processing tokenized train KL dataset:  99%|█████████▊| 3501/3552 [00:08<00:00, 485.54 examples/s]Processing tokenized train KL dataset: 100%|██████████| 3552/3552 [00:09<00:00, 386.34 examples/s]
Filtering desirable examples:   0%|          | 0/3552 [00:00<?, ? examples/s]Filtering desirable examples:  28%|██▊       | 1000/3552 [00:04<00:11, 213.28 examples/s]Filtering desirable examples:  56%|█████▋    | 2000/3552 [00:09<00:07, 215.32 examples/s]Filtering desirable examples:  84%|████████▍ | 3000/3552 [00:13<00:02, 215.53 examples/s]Filtering desirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 215.39 examples/s]Filtering desirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 215.18 examples/s]
Filtering desirable examples:   0%|          | 0/3552 [00:00<?, ? examples/s]Filtering desirable examples:  28%|██▊       | 1000/3552 [00:04<00:12, 210.03 examples/s]Filtering desirable examples:  56%|█████▋    | 2000/3552 [00:09<00:07, 211.28 examples/s]Filtering desirable examples:  84%|████████▍ | 3000/3552 [00:14<00:02, 209.74 examples/s]Filtering desirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 210.73 examples/s]Filtering desirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 210.52 examples/s]
Filtering undesirable examples:   0%|          | 0/3552 [00:00<?, ? examples/s]Filtering undesirable examples:  28%|██▊       | 1000/3552 [00:04<00:11, 215.29 examples/s]Filtering undesirable examples:  56%|█████▋    | 2000/3552 [00:09<00:07, 217.93 examples/s]Filtering undesirable examples:  84%|████████▍ | 3000/3552 [00:14<00:02, 211.10 examples/s]Filtering undesirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 213.68 examples/s]Filtering undesirable examples: 100%|██████████| 3552/3552 [00:16<00:00, 213.88 examples/s]
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:606: UserWarning: 
                        You have different amounts of desirable/positive and undesirable/negative examples but the
                        weights on the desirable and undesirable losses don't seem to be in an ideal range. Based
                        on your data, we recommend EITHER desirable_weight in [1.89, 2.52]
                        or undesirable_weight in [0.4, 0.53] (but NOT BOTH).
                        See the documentation on how to optimally set these weights.
  warnings.warn(
Filtering undesirable examples:   0%|          | 0/3552 [00:00<?, ? examples/s]Filtering undesirable examples:  28%|██▊       | 1000/3552 [00:04<00:12, 208.80 examples/s]Filtering undesirable examples:  56%|█████▋    | 2000/3552 [00:09<00:07, 210.17 examples/s]Filtering undesirable examples:  84%|████████▍ | 3000/3552 [00:14<00:02, 205.36 examples/s]Filtering undesirable examples: 100%|██████████| 3552/3552 [00:17<00:00, 208.06 examples/s]Filtering undesirable examples: 100%|██████████| 3552/3552 [00:17<00:00, 207.87 examples/s]
/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/trl/trainer/kto_trainer.py:606: UserWarning: 
                        You have different amounts of desirable/positive and undesirable/negative examples but the
                        weights on the desirable and undesirable losses don't seem to be in an ideal range. Based
                        on your data, we recommend EITHER desirable_weight in [1.89, 2.52]
                        or undesirable_weight in [0.4, 0.53] (but NOT BOTH).
                        See the documentation on how to optimally set these weights.
  warnings.warn(
Traceback (most recent call last):
  File "/u/qilong/mistral/./KTO2.py", line 334, in <module>
    kto_trainer.train()
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/trainer.py", line 1859, in train
    return inner_training_loop(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/trainer.py", line 2002, in _inner_training_loop
    self.model = self.accelerator.prepare(self.model)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1274, in prepare
    result = tuple(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1275, in <genexpr>
Traceback (most recent call last):
  File "/u/qilong/mistral/./KTO2.py", line 334, in <module>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1151, in _prepare_one
    kto_trainer.train()
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/trainer.py", line 1859, in train
    return self.prepare_model(obj, device_placement=device_placement)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1434, in prepare_model
Traceback (most recent call last):
  File "/u/qilong/mistral/./KTO2.py", line 334, in <module>
    model = FSDP(model, **kwargs)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 477, in __init__
    return inner_training_loop(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/trainer.py", line 2002, in _inner_training_loop
    _auto_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_wrap_utils.py", line 101, in _auto_wrap
    kto_trainer.train()
    self.model = self.accelerator.prepare(self.model)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1274, in prepare
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/trainer.py", line 1859, in train
    _recursive_wrap(**recursive_wrap_kwargs, **root_kwargs)  # type: ignore[arg-type]
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
    result = tuple(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1275, in <genexpr>
    return inner_training_loop(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/trainer.py", line 2002, in _inner_training_loop
Traceback (most recent call last):
    wrapped_child, num_wrapped_params = _recursive_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1151, in _prepare_one
  File "/u/qilong/mistral/./KTO2.py", line 334, in <module>
    self.model = self.accelerator.prepare(self.model)
    wrapped_child, num_wrapped_params = _recursive_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1274, in prepare
    return self.prepare_model(obj, device_placement=device_placement)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1434, in prepare_model
    kto_trainer.train()
    wrapped_child, num_wrapped_params = _recursive_wrap(
  [Previous line repeated 2 more times]
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 561, in _recursive_wrap
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/trainer.py", line 1859, in train
    model = FSDP(model, **kwargs)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 477, in __init__
    result = tuple(
    return _wrap(module, wrapper_cls, **kwargs), nonwrapped_numel
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 490, in _wrap
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1275, in <genexpr>
    _auto_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_wrap_utils.py", line 101, in _auto_wrap
    return inner_training_loop(
    return wrapper_cls(module, **kwargs)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 503, in __init__
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/transformers/trainer.py", line 2002, in _inner_training_loop
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1151, in _prepare_one
    _recursive_wrap(**recursive_wrap_kwargs, **root_kwargs)  # type: ignore[arg-type]
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
    _init_param_handle_from_module(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 590, in _init_param_handle_from_module
    return self.prepare_model(obj, device_placement=device_placement)
    wrapped_child, num_wrapped_params = _recursive_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1434, in prepare_model
    self.model = self.accelerator.prepare(self.model)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1274, in prepare
    _init_param_handle_from_params(state, managed_params, fully_sharded_module)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 602, in _init_param_handle_from_params
    model = FSDP(model, **kwargs)
    wrapped_child, num_wrapped_params = _recursive_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 477, in __init__
    result = tuple(
    handle = FlatParamHandle(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 573, in __init__
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1275, in <genexpr>
    wrapped_child, num_wrapped_params = _recursive_wrap(
  [Previous line repeated 2 more times]
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 561, in _recursive_wrap
    _auto_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_wrap_utils.py", line 101, in _auto_wrap
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1151, in _prepare_one
    return _wrap(module, wrapper_cls, **kwargs), nonwrapped_numel
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 490, in _wrap
    self._init_flat_param_and_metadata(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 623, in _init_flat_param_and_metadata
    _recursive_wrap(**recursive_wrap_kwargs, **root_kwargs)  # type: ignore[arg-type]
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
    return wrapper_cls(module, **kwargs)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 503, in __init__
    return self.prepare_model(obj, device_placement=device_placement)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/accelerate/accelerator.py", line 1434, in prepare_model
    ) = self._validate_tensors_to_flatten(params)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 761, in _validate_tensors_to_flatten
    wrapped_child, num_wrapped_params = _recursive_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
    _init_param_handle_from_module(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 590, in _init_param_handle_from_module
    model = FSDP(model, **kwargs)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 477, in __init__
    raise ValueError(
ValueError: Must flatten tensors with uniform dtype but got torch.bfloat16 and torch.float32
    _init_param_handle_from_params(state, managed_params, fully_sharded_module)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 602, in _init_param_handle_from_params
    wrapped_child, num_wrapped_params = _recursive_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
    _auto_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_wrap_utils.py", line 101, in _auto_wrap
    handle = FlatParamHandle(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 573, in __init__
    wrapped_child, num_wrapped_params = _recursive_wrap(
  [Previous line repeated 2 more times]
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 561, in _recursive_wrap
    _recursive_wrap(**recursive_wrap_kwargs, **root_kwargs)  # type: ignore[arg-type]
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
    return _wrap(module, wrapper_cls, **kwargs), nonwrapped_numel
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 490, in _wrap
    self._init_flat_param_and_metadata(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 623, in _init_flat_param_and_metadata
    return wrapper_cls(module, **kwargs)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 503, in __init__
    wrapped_child, num_wrapped_params = _recursive_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
    ) = self._validate_tensors_to_flatten(params)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 761, in _validate_tensors_to_flatten
    _init_param_handle_from_module(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 590, in _init_param_handle_from_module
    wrapped_child, num_wrapped_params = _recursive_wrap(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 543, in _recursive_wrap
    raise ValueError(
ValueError: Must flatten tensors with uniform dtype but got torch.bfloat16 and torch.float32
    wrapped_child, num_wrapped_params = _recursive_wrap(
  [Previous line repeated 2 more times]
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 561, in _recursive_wrap
    _init_param_handle_from_params(state, managed_params, fully_sharded_module)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 602, in _init_param_handle_from_params
    return _wrap(module, wrapper_cls, **kwargs), nonwrapped_numel
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/wrap.py", line 490, in _wrap
    handle = FlatParamHandle(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 573, in __init__
    return wrapper_cls(module, **kwargs)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 503, in __init__
    self._init_flat_param_and_metadata(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 623, in _init_flat_param_and_metadata
    _init_param_handle_from_module(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 590, in _init_param_handle_from_module
    ) = self._validate_tensors_to_flatten(params)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 761, in _validate_tensors_to_flatten
    _init_param_handle_from_params(state, managed_params, fully_sharded_module)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 602, in _init_param_handle_from_params
    raise ValueError(
ValueError: Must flatten tensors with uniform dtype but got torch.bfloat16 and torch.float32
    handle = FlatParamHandle(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 573, in __init__
    self._init_flat_param_and_metadata(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 623, in _init_flat_param_and_metadata
    ) = self._validate_tensors_to_flatten(params)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 761, in _validate_tensors_to_flatten
    raise ValueError(
ValueError: Must flatten tensors with uniform dtype but got torch.bfloat16 and torch.float32
[2024-05-31 17:52:37,535] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4175356) of binary: /u/qilong/utils/miniconda3/envs/rag/bin/python3.10
[2024-05-31 17:52:37,538] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 673981) of binary: /u/qilong/utils/miniconda3/envs/rag/bin/python3.10
[2024-05-31 17:52:37,540] torch.distributed.elastic.multiprocessing.errors: [INFO] ('local_rank %s FAILED with no error file. Decorate your entrypoint fn with @record for traceback info. See: https://pytorch.org/docs/stable/elastic/errors.html', 0)
Traceback (most recent call last):
  File "/u/qilong/utils/miniconda3/envs/rag/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
[2024-05-31 17:52:37,542] torch.distributed.elastic.multiprocessing.errors: [INFO] ('local_rank %s FAILED with no error file. Decorate your entrypoint fn with @record for traceback info. See: https://pytorch.org/docs/stable/elastic/errors.html', 2)
Traceback (most recent call last):
  File "/u/qilong/utils/miniconda3/envs/rag/bin/torchrun", line 8, in <module>
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    sys.exit(main())
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
./KTO2.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-05-31_17:52:37
  host      : hydro05.internal.ncsa.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 4175357)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-05-31_17:52:37
  host      : hydro05.internal.ncsa.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4175356)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/u/qilong/utils/miniconda3/envs/rag/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
./KTO2.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-05-31_17:52:37
  host      : hydro06.internal.ncsa.edu
  rank      : 3 (local_rank: 1)
  exitcode  : 1 (pid: 673982)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-05-31_17:52:37
  host      : hydro06.internal.ncsa.edu
  rank      : 2 (local_rank: 0)
  exitcode  : 1 (pid: 673981)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: hydro06: task 1: Exited with exit code 1
srun: error: hydro05: task 0: Exited with exit code 1
