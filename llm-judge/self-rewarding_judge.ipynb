{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe6707c-23bc-4063-b5c4-c74cc0cf7e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /u/sy63/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "!huggingface-cli login --token \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a66ac7-483a-4c88-9bef-1c6dd44b5240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 12 11:47:10 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:21:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             43W /  300W |       0MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e846a99b-fcd2-43ca-8d20-13662977d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"CAII-NCSA/critique_ECE408_FA23_first_interactions\")\n",
    "\n",
    "first_query = dataset['train'][\"first_query\"]\n",
    "first_response = dataset['train'][\"first_response\"]\n",
    "full_prompt = dataset['train']['full_prompt']\n",
    "critique = dataset['train']['critique']\n",
    "\n",
    "data = {'first_query': first_query,\n",
    "     'first_response': first_response,\n",
    "     \"full_prompt\": full_prompt,\n",
    "       \"critique\": critique\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "subset_dataset = df.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c982837-a073-47ff-807b-4f5173e08460",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53d7f76-3ff1-495d-a1d7-47474dfaefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_PROMPT = \"\"\"\n",
    "You will be given a full_prompt and first_query couple.\n",
    "Your task is to provide a 'total rating' scoring how well the system_answer answers the user concerns expressed in the user_question.\n",
    "Review the user’s question and the corresponding response using a 10-point scoring system based on the following criteria:\n",
    "\n",
    "1. Completeness: Add 1 point if the response addresses all aspects of the question in a holistic manner.\n",
    "2. Factuality: Add 1 point if the response is accurate and based on factual information.\n",
    "3. Helpfulness: Add 1 point if the response is likely to be useful to the user in addressing their concern or question.\n",
    "4. Harmlessness: Add 1 point if the response avoids causing harm or spreading misinformation.\n",
    "5. Freshness: Add 1 point if the response includes up-to-date information or perspectives.\n",
    "6. Supported: Add 1 point if the response provides evidence or sources supporting the claims or information presented.\n",
    "7. Retrieval necessary: Add 1 point if the answer benefits significantly from web retrieval or would benefit from such information.\n",
    "8. Includes examples: Add 1 point if the response includes examples or analogies that help clarify the answer.\n",
    "9. Useful: Add 1 point if the response provides actionable advice or insights beyond the basic answer.\n",
    "10. AI Perspective: Add 1 point if the response is clearly from an AI, focusing on direct and comprehensive answering from an AI perspective.\n",
    "\n",
    "Provide your feedback as follows:\n",
    "\n",
    "Feedback:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (additive points from the prompt, as a number between 0 and 10)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Score:' in your answer.\n",
    "Conclude with the score using the format: “Score: <Total rating>”\n",
    "\n",
    "Now here are the question and answer.\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ef6421-78f2-4e8f-8ae6-087b48f9b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "llm_client = InferenceClient(\n",
    "    model=repo_id,\n",
    "    timeout=120,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12ddec8-256e-42f2-9088-5c97f5756f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_883931/3420700850.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_dataset[\"llm_judge\"] = subset_dataset.apply(generate_text, axis=1)\n",
      "/tmp/ipykernel_883931/3420700850.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_dataset[\"llm_judge_score\"] = subset_dataset[\"llm_judge\"].apply(extract_judge_score)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_query</th>\n",
       "      <th>first_response</th>\n",
       "      <th>full_prompt</th>\n",
       "      <th>critique</th>\n",
       "      <th>llm_judge</th>\n",
       "      <th>llm_judge_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explain how tiling helps with global memory ba...</td>\n",
       "      <td>Tiling is a technique used in CUDA programming...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>1. The answer could benefit from a more concis...</td>\n",
       "      <td>\\nFeedback:::\\nEvaluation: The system_answer i...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Show an example of [CUDA API] function usage.</td>\n",
       "      <td>Sure, here are a few examples of CUDA API func...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>1. The model-generated answer is generally cor...</td>\n",
       "      <td>\\n\\nFeedback:::\\nEvaluation: The response is c...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is my chance to get into ece master at ui...</td>\n",
       "      <td>I'm sorry, but the documents provided do not c...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>The model-generated answer is technically corr...</td>\n",
       "      <td>\\nFeedback:::\\nEvaluation: This response does ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how tiling helps with global memory ba...</td>\n",
       "      <td>Tiling is a technique that helps optimize the ...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>The model-generated answer provides a good exp...</td>\n",
       "      <td>\\nFeedback:::\\nEvaluation: The answer provides...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When is the first midterm exam?</td>\n",
       "      <td>The first midterm exam is scheduled after appr...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>The model-generated answer is generally inform...</td>\n",
       "      <td>\\nFeedback:::\\nEvaluation: The system answer i...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NVIDIA A40 is which NVIDIA architecture?</td>\n",
       "      <td>The NVIDIA A40 GPU is based on the NVIDIA Ampe...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>The model-generated answer is mostly correct, ...</td>\n",
       "      <td>\\n\\nFeedback:::\\nEvaluation: The response is c...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>How do I allocate GPU memory</td>\n",
       "      <td>To allocate GPU memory in CUDA, you typically ...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>The model-generated answer is generally accura...</td>\n",
       "      <td>\\nFeedback:::\\nEvaluation: The answer is compl...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>a warp of threads meaning</td>\n",
       "      <td>A warp of threads refers to a group of threads...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>1. While the answer accurately describes what ...</td>\n",
       "      <td>\\n\\n\\nFeedback:::\\nEvaluation: The response is...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>What is a good number for threads per block fo...</td>\n",
       "      <td>When parallelizing operations on a long 1D vec...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>1. The model-generated answer provides a good ...</td>\n",
       "      <td>\\n\\nFeedback:::\\nEvaluation: The answer is hig...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>threadIdx and blockIdx are two built-in variab...</td>\n",
       "      <td>Yes, `threadIdx` and `blockIdx` are indeed bui...</td>\n",
       "      <td>\\nPlease analyze and respond to the following ...</td>\n",
       "      <td>The model-generated answer is generally correc...</td>\n",
       "      <td>\\nFeedback:::\\nEvaluation: The answer is a com...</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          first_query  \\\n",
       "0   Explain how tiling helps with global memory ba...   \n",
       "1       Show an example of [CUDA API] function usage.   \n",
       "2   what is my chance to get into ece master at ui...   \n",
       "3   Explain how tiling helps with global memory ba...   \n",
       "4                     When is the first midterm exam?   \n",
       "..                                                ...   \n",
       "95           NVIDIA A40 is which NVIDIA architecture?   \n",
       "96                       How do I allocate GPU memory   \n",
       "97                          a warp of threads meaning   \n",
       "98  What is a good number for threads per block fo...   \n",
       "99  threadIdx and blockIdx are two built-in variab...   \n",
       "\n",
       "                                       first_response  \\\n",
       "0   Tiling is a technique used in CUDA programming...   \n",
       "1   Sure, here are a few examples of CUDA API func...   \n",
       "2   I'm sorry, but the documents provided do not c...   \n",
       "3   Tiling is a technique that helps optimize the ...   \n",
       "4   The first midterm exam is scheduled after appr...   \n",
       "..                                                ...   \n",
       "95  The NVIDIA A40 GPU is based on the NVIDIA Ampe...   \n",
       "96  To allocate GPU memory in CUDA, you typically ...   \n",
       "97  A warp of threads refers to a group of threads...   \n",
       "98  When parallelizing operations on a long 1D vec...   \n",
       "99  Yes, `threadIdx` and `blockIdx` are indeed bui...   \n",
       "\n",
       "                                          full_prompt  \\\n",
       "0   \\nPlease analyze and respond to the following ...   \n",
       "1   \\nPlease analyze and respond to the following ...   \n",
       "2   \\nPlease analyze and respond to the following ...   \n",
       "3   \\nPlease analyze and respond to the following ...   \n",
       "4   \\nPlease analyze and respond to the following ...   \n",
       "..                                                ...   \n",
       "95  \\nPlease analyze and respond to the following ...   \n",
       "96  \\nPlease analyze and respond to the following ...   \n",
       "97  \\nPlease analyze and respond to the following ...   \n",
       "98  \\nPlease analyze and respond to the following ...   \n",
       "99  \\nPlease analyze and respond to the following ...   \n",
       "\n",
       "                                             critique  \\\n",
       "0   1. The answer could benefit from a more concis...   \n",
       "1   1. The model-generated answer is generally cor...   \n",
       "2   The model-generated answer is technically corr...   \n",
       "3   The model-generated answer provides a good exp...   \n",
       "4   The model-generated answer is generally inform...   \n",
       "..                                                ...   \n",
       "95  The model-generated answer is mostly correct, ...   \n",
       "96  The model-generated answer is generally accura...   \n",
       "97  1. While the answer accurately describes what ...   \n",
       "98  1. The model-generated answer provides a good ...   \n",
       "99  The model-generated answer is generally correc...   \n",
       "\n",
       "                                            llm_judge  llm_judge_score  \n",
       "0   \\nFeedback:::\\nEvaluation: The system_answer i...              8.0  \n",
       "1   \\n\\nFeedback:::\\nEvaluation: The response is c...             10.0  \n",
       "2   \\nFeedback:::\\nEvaluation: This response does ...              2.0  \n",
       "3   \\nFeedback:::\\nEvaluation: The answer provides...             11.0  \n",
       "4   \\nFeedback:::\\nEvaluation: The system answer i...              8.0  \n",
       "..                                                ...              ...  \n",
       "95  \\n\\nFeedback:::\\nEvaluation: The response is c...             10.0  \n",
       "96  \\nFeedback:::\\nEvaluation: The answer is compl...              9.0  \n",
       "97  \\n\\n\\nFeedback:::\\nEvaluation: The response is...              9.0  \n",
       "98  \\n\\nFeedback:::\\nEvaluation: The answer is hig...              1.0  \n",
       "99  \\nFeedback:::\\nEvaluation: The answer is a com...              9.5  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(row):\n",
    "    prompt = JUDGE_PROMPT.format(question=row['first_query'], answer=row['first_response'])\n",
    "    return llm_client.text_generation(\n",
    "        prompt=prompt,\n",
    "        max_new_tokens=1000,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    generated_text = response.choices[0].text.strip()\n",
    "    return generated_text\n",
    "\n",
    "subset_dataset[\"llm_judge\"] = subset_dataset.apply(generate_text, axis=1)\n",
    "\n",
    "def extract_judge_score(answer: str, split_str: str = \"Score:\") -> int:\n",
    "    try:\n",
    "        if split_str in answer:\n",
    "            rating = answer.split(split_str)[1]\n",
    "        else:\n",
    "            rating = answer\n",
    "        digit_groups = [el.strip() for el in re.findall(r\"\\d+(?:\\.\\d+)?\", rating)]\n",
    "        return float(digit_groups[0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "subset_dataset[\"llm_judge_score\"] = subset_dataset[\"llm_judge\"].apply(extract_judge_score)\n",
    "subset_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860e1ece-93c0-4e50-b003-ecc1eeb2ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dataset.to_csv('subset_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed215b6b-ec83-4442-8fa9-c3b823f575cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
